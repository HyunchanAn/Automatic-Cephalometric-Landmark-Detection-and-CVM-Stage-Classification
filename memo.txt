## 프로젝트 재현 및 AI 모델 훈련 환경 구축 기록

### 1. 프로젝트 분석
- `README.md`와 소스 코드를 분석하여, 이 프로젝트가 'Aariz'라는 두부 계측 방사선 사진 데이터셋을 제공하는 것이 주 목적임을 파악했습니다.
- `dataset.py`를 통해 데이터셋의 기본적인 로드 방법을 확인했습니다.

### 2. 데이터셋 확보 및 준비
- 웹 검색을 통해 Figshare에 공유된 데이터셋의 다운로드 링크를 찾아냈습니다.
- 사용자가 `Aariz` 폴더에 데이터셋을 준비했고, 폴더 내 `readme.txt`를 읽어 데이터의 상세 구조를 파악했습니다.

### 3. 데이터 로딩 및 디버깅
- `dataset.py`를 사용하여 데이터 로드를 시도했으나, 라이브러리 누락 (`numpy`, `opencv-python`) 및 오래된 코드 (`np.float`)로 인해 오류가 발생했습니다.
- 필요한 라이브러리를 설치하고, `np.float`를 `np.float64`로 수정하여 모든 오류를 해결했습니다.
- 최종적으로 데이터셋의 첫 번째 샘플(이미지, 랜드마크, CVM 단계)을 성공적으로 불러오는 데 성공했습니다.

### 4. AI 모델 훈련 환경 구축
- 사용자의 요청에 따라, PyTorch 기반의 AI 모델 훈련 환경 구성을 시작했습니다.
- `torch`, `torchvision` 라이브러리를 설치했습니다.
- `dataset.py`를 PyTorch의 `DataLoader`와 호환되도록 수정했습니다.
- `model.py` 파일을 새로 생성하고, 랜드마크 예측과 CVM 분류를 위한 두 개의 출력 헤드를 가진 기본 CNN 모델(`CephNet`)의 뼈대를 정의했습니다.
- `train.py` 파일을 새로 생성하고, 데이터 로딩, 모델 초기화, 손실 함수, 옵티마이저 설정 및 기본적인 훈련 루프를 포함한 전체 훈련 프로세스를 구현했습니다.

### 5. 최종 설정
- `train.py`의 이미지 크기(256x256)에 맞춰 `model.py`의 `fc_input_size` 변수의 정확한 값을 계산했습니다.
- 계산된 값(`65536`)으로 `model.py`를 업데이트하여, 모델이 훈련을 시작할 수 있도록 최종 준비를 마쳤습니다.

### 6. 모델 생성 및 저장 (.pth 파일)
- `train.py` 스크립트를 실행하여 `CephNet` 모델의 훈련을 진행했습니다.
- 훈련이 완료된 후, 모델의 학습된 가중치(weights)를 `cephnet_model.pth` 파일로 저장했습니다.

### 7. 추가 훈련 및 모델 활용
- **추가 훈련:** `train.py` 파일의 `EPOCHS` 값을 원하는 만큼 늘린 후, 터미널에서 `python train.py`를 다시 실행하면 마지막으로 저장된 상태에서 훈련을 이어서 계속할 수 있습니다. (참고: 현재 코드는 마지막 상태를 이어가는 것이 아니라, 처음부터 다시 훈련합니다. 훈련을 이어가려면 모델을 불러오는 코드를 `train.py`에 추가해야 합니다.)
- **저장된 모델 불러오기:** 저장된 `cephnet_model.pth` 파일을 사용하여 예측이나 추가 훈련을 하려면, 다음과 같은 코드를 사용합니다.

```python
import torch
from model import CephNet

# 1. 모델 구조를 먼저 정의합니다.
model = CephNet()

# 2. 저장된 가중치를 불러와 모델에 적용합니다.
model.load_state_dict(torch.load('cephnet_model.pth'))

# 3. 모델을 평가 모드로 설정합니다. (예측에 사용하는 경우)
model.eval()

# 이제 `model` 변수를 사용하여 예측 등을 수행할 수 있습니다.
```

### 8. 모델 성능 향상 (데이터 증강 및 검증)
- **개념:** 모델의 일반화 성능을 높이고 과적합을 방지하기 위해, 훈련 데이터에 인위적인 변화를 주어 데이터의 양을 늘리는 기법입니다.
- **구현:** `train.py`의 훈련 데이터 로더에 `RandomHorizontalFlip` (무작위 좌우 반전)과 `RandomRotation` (무작위 회전) 변환을 추가했습니다. 이 변환들은 훈련 시에만 적용되며, 모델이 다양한 각도와 방향의 이미지에 대응할 수 있도록 학습시킵니다.
- **검증 추가:** 매 에포크 훈련이 끝날 때마다, 데이터 증강을 적용하지 않은 별도의 '검증 데이터셋(validation dataset)'으로 모델의 성능을 평가하는 로직을 추가했습니다. 훈련 손실(Train Loss)과 함께 검증 손실(Validation Loss)이 출력되며, 이 검증 손실값을 통해 모델의 실제 성능과 과적합 여부를 더 객관적으로 파악할 수 있습니다.
- **사용법:** 사용법은 이전과 동일합니다. 터미널에서 `python train.py`를 실행하면 데이터 증강이 적용된 훈련과 검증이 함께 진행됩니다.

### 9. 추가 작업 및 오류 수정
- **검증 데이터셋 부재:** 훈련 스크립트 실행 중, `Aariz` 폴더 내에 `valid` 폴더가 없어 발생하는 `FileNotFoundError`를 확인했습니다.
- **경로 처리 로직 수정:** `dataset.py`에서 데이터셋 모드(`TRAIN`, `VALID`, `TEST`)를 처리할 때, 폴더명과 일치하도록 `capitalize()`(첫 글자만 대문자) 대신 `lower()`(모두 소문자)를 사용하도록 코드를 수정하여 향후 발생할 수 있는 경로 문제를 예방했습니다.
- **검증 데이터셋 생성:** `train` 데이터셋의 일부를 사용하여 `valid` 데이터셋을 생성하기로 결정하고, `Aariz/valid` 경로와 그 하위 폴더(Cephalograms, Annotations 등)를 생성했습니다. 그 후, `split_dataset.py` 스크립트를 작성하여 `train` 데이터셋의 20%를 `valid` 폴더로 이동시켜 검증 데이터셋 구축을 완료했습니다.