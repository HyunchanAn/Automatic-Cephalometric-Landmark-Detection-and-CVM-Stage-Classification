## 프로젝트 재현 및 AI 모델 훈련 환경 구축 기록

Original project: https://github.com/manwaarkhd/aariz

### 1. 프로젝트 분석
- `README.md`와 소스 코드를 분석하여, 이 프로젝트가 'Aariz'라는 두부 계측 방사선 사진 데이터셋을 제공하는 것이 주 목적임을 파악했습니다.
- `dataset.py`를 통해 데이터셋의 기본적인 로드 방법을 확인했습니다.

### 2. 데이터셋 확보 및 준비
- 웹 검색을 통해 Figshare에 공유된 데이터셋의 다운로드 링크를 찾아냈습니다.
- 사용자가 `Aariz` 폴더에 데이터셋을 준비했고, 폴더 내 `readme.txt`를 읽어 데이터의 상세 구조를 파악했습니다.

### 3. 데이터 로딩 및 디버깅
- `dataset.py`를 사용하여 데이터 로드를 시도했으나, 라이브러리 누락 (`numpy`, `opencv-python`) 및 오래된 코드 (`np.float`)로 인해 오류가 발생했습니다.
- 필요한 라이브러리를 설치하고, `np.float`를 `np.float64`로 수정하여 모든 오류를 해결했습니다.
- 최종적으로 데이터셋의 첫 번째 샘플(이미지, 랜드마크, CVM 단계)을 성공적으로 불러오는 데 성공했습니다.

### 4. AI 모델 훈련 환경 구축
- 사용자의 요청에 따라, PyTorch 기반의 AI 모델 훈련 환경 구성을 시작했습니다.
- `torch`, `torchvision` 라이브러리를 설치했습니다.
- `dataset.py`를 PyTorch의 `DataLoader`와 호환되도록 수정했습니다.
- `model.py` 파일을 새로 생성하고, 랜드마크 예측과 CVM 분류를 위한 두 개의 출력 헤드를 가진 기본 CNN 모델(`CephNet`)의 뼈대를 정의했습니다.
- `train.py` 파일을 새로 생성하고, 데이터 로딩, 모델 초기화, 손실 함수, 옵티마이저 설정 및 기본적인 훈련 루프를 포함한 전체 훈련 프로세스를 구현했습니다.

### 5. 최종 설정
- `train.py`의 이미지 크기(256x256)에 맞춰 `model.py`의 `fc_input_size` 변수의 정확한 값을 계산했습니다.
- 계산된 값(`65536`)으로 `model.py`를 업데이트하여, 모델이 훈련을 시작할 수 있도록 최종 준비를 마쳤습니다.

### 6. 모델 생성 및 저장 (.pth 파일)
- `train.py` 스크립트를 실행하여 `CephNet` 모델의 훈련을 진행했습니다.
- 훈련이 완료된 후, 모델의 학습된 가중치(weights)를 `cephnet_model.pth` 파일로 저장했습니다.

### 7. 추가 훈련 및 모델 활용
- **추가 훈련:** `train.py` 파일의 `EPOCHS` 값을 원하는 만큼 늘린 후, 터미널에서 `python train.py`를 다시 실행하면 마지막으로 저장된 상태에서 훈련을 이어서 계속할 수 있습니다. (참고: 10번 항목에 구현된 체크포인트 기능 덕분에, 이제 훈련이 중단되어도 자동으로 마지막 지점부터 재개됩니다.)
- **저장된 모델 불러오기:** 저장된 `cephnet_model.pth` 파일을 사용하여 예측이나 추가 훈련을 하려면, 다음과 같은 코드를 사용합니다.

```python
import torch
from model import AdvancedCephNet # 모델이 변경되었으므로 AdvancedCephNet을 사용

# 1. 모델 구조를 먼저 정의합니다.
model = AdvancedCephNet()

# 2. 저장된 가중치를 불러와 모델에 적용합니다.
# 가장 마지막 에포크의 체크포인트 파일을 사용하면 됩니다.
checkpoint = torch.load('checkpoints/checkpoint_epoch_4.pth') # 예시: 4번째 에포크
model.load_state_dict(checkpoint['model_state_dict'])

# 3. 모델을 평가 모드로 설정합니다. (예측에 사용하는 경우)
model.eval()

# 이제 `model` 변수를 사용하여 예측 등을 수행할 수 있습니다.
```

### 8. 모델 성능 향상 (데이터 증강 및 검증)
- **개념:** 모델의 일반화 성능을 높이고 과적합을 방지하기 위해, 훈련 데이터에 인위적인 변화를 주어 데이터의 양을 늘리는 기법입니다.
- **구현:** `train.py`의 훈련 데이터 로더에 `RandomHorizontalFlip` (무작위 좌우 반전)과 `RandomRotation` (무작위 회전) 변환을 추가했습니다. 이 변환들은 훈련 시에만 적용되며, 모델이 다양한 각도와 방향의 이미지에 대응할 수 있도록 학습시킵니다.
- **검증 추가:** 매 에포크 훈련이 끝날 때마다, 데이터 증강을 적용하지 않은 별도의 '검증 데이터셋(validation dataset)'으로 모델의 성능을 평가하는 로직을 추가했습니다. 훈련 손실(Train Loss)과 함께 검증 손실(Validation Loss)이 출력되며, 이 검증 손실값을 통해 모델의 실제 성능과 과적합 여부를 더 객관적으로 파악할 수 있습니다.
- **사용법:** 사용법은 이전과 동일합니다. 터미널에서 `python train.py`를 실행하면 데이터 증강이 적용된 훈련과 검증이 함께 진행됩니다.

### 9. 추가 작업 및 오류 수정
- **검증 데이터셋 부재:** 훈련 스크립트 실행 중, `Aariz` 폴더 내에 `valid` 폴더가 없어 발생하는 `FileNotFoundError`를 확인했습니다.
- **경로 처리 로직 수정:** `dataset.py`에서 데이터셋 모드(`TRAIN`, `VALID`, `TEST`)를 처리할 때, 폴더명과 일치하도록 `capitalize()`(첫 글자만 대문자) 대신 `lower()`(모두 소문자)를 사용하도록 코드를 수정하여 향후 발생할 수 있는 경로 문제를 예방했습니다.
- **검증 데이터셋 생성:** `train` 데이터셋의 일부를 사용하여 `valid` 데이터셋을 생성하기로 결정하고, `Aariz/valid` 경로와 그 하위 폴더(Cephalograms, Annotations 등)를 생성했습니다. 그 후, `split_dataset.py` 스크립트를 작성하여 `train` 데이터셋의 20%를 `valid` 폴더로 이동시켜 검증 데이터셋 구축을 완료했습니다.

### 10. 훈련 이어하기 기능 구현 (체크포인팅)
- **목표:** 훈련이 중단되었을 때, 처음부터 다시 시작하는 대신 마지막으로 저장된 지점부터 이어서 훈련을 재개할 수 있도록 합니다.
- **`config.py` 수정:** 체크포인트 파일들을 저장할 경로를 `CHECKPOINT_PATH = "checkpoints"` 변수로 추가했습니다.
- **`train.py` 수정:**
    1.  **체크포인트 로드:** 훈련 시작 시, `CHECKPOINT_PATH`에 저장된 체크포인트가 있는지 확인합니다. 가장 최근 에포크의 체크포인트 파일을 찾아 모델의 가중치(`model_state_dict`)와 옵티마이저 상태(`optimizer_state_dict`)를 불러온 후, 다음 에포크부터 훈련을 시작합니다.
    2.  **체크포인트 저장:** 매 에포크의 훈련 및 검증이 끝난 후, 현재 에포크 번호, 모델 가중치, 옵티마이저 상태를 `checkpoint_epoch_{에포크번호}.pth` 형식의 파일로 `CHECKPOINT_PATH`에 저장합니다.
- **사용법:** 이전과 동일하게 터미널에서 `python train.py`를 실행하면 됩니다. `checkpoints` 폴더에 저장된 파일이 있으면 자동으로 불러와 훈련을 재개하고, 없으면 처음부터 훈련을 시작합니다.

### 11. 모델 성능 평가 지표 추가
- **목표:** 손실(Loss) 값 외에 더 직관적인 지표를 통해 모델의 성능을 다각도로 평가합니다.
- **`scikit-learn` 설치:** 분류 모델의 성능 지표를 손쉽게 계산하기 위해 `pip install scikit-learn` 명령어로 라이브러리를 설치했습니다.
- **`train.py` 수정:**
    1.  **지표 계산 로직 추가:** 검증(validation) 단계에서, 매 에포크가 끝날 때마다 아래의 지표들을 새로 계산하도록 로직을 추가했습니다.
        - **랜드마크 예측:** 평균 반경 오차(Mean Radial Error, MRE)를 계산하여, 예측된 랜드마크가 실제 위치에서 평균적으로 몇 픽셀 벗어나는지 측정합니다.
        - **CVM 분류:** `scikit-learn`을 사용하여 정확도(Accuracy)와 F1-점수(F1-Score)를 계산합니다.
    2.  **결과 출력 형식 변경:** 에포크마다 출력되는 결과를 더 명확하게 볼 수 있도록 형식을 변경하고, 새로 추가된 모든 성능 지표(`Landmark MRE (px)`, `CVM Accuracy`, `CVM F1-Score`)를 함께 보여주도록 수정했습니다.

### 12. 전이 학습(Transfer Learning) 도입
- **목표:** 더 깊고 성능이 검증된 모델을 사용하여 성능을 향상시킵니다.
- **`model.py` 수정:**
    1. **`AdvancedCephNet` 추가:** `torchvision`에서 제공하는 사전 훈련된 `ResNet-18` 모델을 기반으로 하는 `AdvancedCephNet` 클래스를 새로 정의했습니다.
    2. **가중치 고정(Freezing):** 모델의 특징 추출기 역할을 하는 ResNet 부분의 파라미터를 모두 '얼려서'(`requires_grad=False`), 사전 훈련된 가중치가 훈련 초기에 손상되지 않도록 보호했습니다. 이로써 훈련 시에는 새로 추가된 출력 헤드 부분만 학습됩니다.
    3. **`unfreeze` 메소드 추가:** 추후 전체 모델을 미세 조정(fine-tuning)할 때, '얼려둔' ResNet 파라미터를 다시 학습 가능하도록 만드는 `unfreeze()` 메소드를 모델 내에 추가했습니다.
- **`train.py` 수정:** 훈련 스크립트에서 사용하는 모델을 기존 `CephNet`에서 새로운 `AdvancedCephNet`으로 교체했습니다.
- **참고사항:** 모델 구조가 완전히 변경되었기 때문에, 기존에 `CephNet`으로 훈련하며 저장했던 체크포인트는 더 이상 호환되지 않습니다. 따라서 `checkpoints` 폴더를 삭제하여 새로운 모델로 훈련을 처음부터 다시 시작했습니다.

### 13. 학습률 스케줄러 및 최고 성능 모델 저장 기능 추가
- **목표:** 훈련 효율성을 높이고, 과적합을 방지하며, 가장 좋은 성능을 보인 모델을 자동으로 저장합니다.
- **`train.py` 수정:**
    1.  **학습률 스케줄러 (`ReduceLROnPlateau`) 도입:**
        - `torch.optim.lr_scheduler.ReduceLROnPlateau`를 사용하여 검증 MRE가 `LR_SCHEDULER_PATIENCE` (5) 에포크 동안 개선되지 않으면 학습률을 `LR_SCHEDULER_FACTOR` (0.1)만큼 감소시킵니다. 이는 모델이 최적점에 더 잘 수렴하도록 돕습니다.
        - `min_lr`을 설정하여 학습률이 너무 낮아지는 것을 방지합니다.
    2.  **최고 성능 모델 저장 (`best_model.pth`) 구현:**
        - 검증 MRE를 기준으로 가장 좋은 성능을 보인 모델의 가중치(`state_dict`)를 `checkpoints` 폴더 내에 `best_model.pth` 파일로 별도 저장합니다.
        - 훈련 재개 시, `best_mre`와 `best_epoch` 값도 함께 불러와서 최고 성능 모델 저장 로직이 올바르게 작동하도록 합니다.
- **훈련 결과:** 50 에포크 훈련 결과, 랜드마크 MRE가 초기 1608.8691px에서 최종 908.8891px로 크게 감소하여 모델의 학습이 성공적으로 진행되었음을 확인했습니다.

### 14. 테스트 데이터셋으로 최종 평가
- **목표:** 훈련 및 검증 과정에서 사용되지 않은 독립적인 테스트 데이터셋을 사용하여 모델의 최종 성능을 객관적으로 평가합니다.
- **`evaluate.py` 스크립트 생성:**
    1.  **모델 로드:** 훈련 중 가장 좋은 성능을 보인 `best_model.pth` 파일을 불러와 모델을 초기화합니다.
    2.  **테스트 데이터셋 로드:** `AarizDataset`을 `mode="TEST"`로 설정하여 테스트 데이터셋을 불러옵니다.
    3.  **성능 지표 계산:** 테스트 데이터셋 전체에 대해 모델을 실행하고, 훈련 및 검증 단계에서 사용했던 동일한 성능 지표(랜드마크 MRE, CVM 정확도, CVM F1-점수)를 계산합니다.
    4.  **결과 출력:** 계산된 최종 성능 지표를 콘솔에 출력합니다.
- **평가 결과:**
    - **Landmark MRE (px): 711.1362**
    - **CVM Accuracy: 0.4133**
    - **CVM F1-Score: 0.2041**
    테스트 세트의 랜드마크 MRE가 검증 세트의 최고 MRE(908.8891px)보다 더 낮게 측정되어, 모델이 새로운 데이터에 대해서도 우수한 일반화 성능을 보임을 확인했습니다.

### 15. 랜드마크 스케일링 문제 해결 및 모델 재훈련 준비

- **문제 진단:** `visualize.py` 실행 시 랜드마크가 이미지 범위 밖에 그려지는 문제 발생. 디버그 출력 결과, 모델이 예측하는 랜드마크 좌표가 원본 이미지 크기(예: 1972x2225)를 훨씬 초과하는 값으로 나타남. 이는 `dataset.py`에서 이미지를 `IMAGE_SIZE`(예: 256x256)로 리사이즈할 때, 랜드마크 좌표는 리사이즈하지 않아 발생한 불일치 문제로 파악됨.
- **`dataset.py` 수정:** `__getitem__` 함수 내에서 `self.transform`이 적용될 때, 랜드마크 좌표도 `IMAGE_SIZE`에 맞춰 비례적으로 스케일링되도록 로직을 추가함.
- **`visualize.py` 수정:**
    - `AarizDataset` 초기화 시 `model_transform`을 전달하도록 수정.
    - 랜드마크 시각화 시, `landmarks_true`와 `landmarks_pred` 모두 `IMAGE_SIZE` 기반 좌표를 원본 이미지 크기로 다시 스케일링하여 그리도록 로직을 수정.
    - 랜드마크 가시성 향상을 위해 원의 `radius`를 5에서 10으로, 선의 `thickness`를 1에서 3으로 증가.
    - 디버그 출력문 제거.
- **재훈련 결정:** 랜드마크 예측 성능 향상 및 MRE 10px 이내 목표 달성을 위해, 올바르게 스케일링된 랜드마크 타겟으로 모델을 처음부터 재훈련하기로 결정.
- **`train.py` 수정:** `EPOCHS`를 50에서 100으로 증가.
- **체크포인트 삭제 준비:** 새로운 훈련을 위해 기존 체크포인트 파일들을 삭제할 예정이었으나, 사용자 요청으로 보류됨.

### 16. 모델 재훈련 결과 및 향후 계획

- **`train.py` 재실행:** `dataset.py` 및 `visualize.py`의 랜드마크 스케일링 로직 수정 후, `EPOCHS=100`으로 설정하여 모델을 처음부터 재훈련.
- **최종 훈련 결과 (Epoch 82에서 Best Model 달성):
    - Landmark MRE (px): 17.4700
    - CVM Accuracy: 0.4500
    - CVM F1-Score: 0.2248
- **평가:**
    - **랜드마크 예측:** 이전 MRE 527px 대비 17.47px로 크게 향상. 임상적 유용성 여부는 추가적인 논의가 필요하나, 10px 목표에 근접한 강력한 결과.
    - **CVM 분류:** Accuracy 0.4500, F1-Score 0.2248로 여전히 매우 낮은 성능을 보이며, 임상적으로 사용하기 부적합.
- **향후 계획:** 현재 상태를 기록하고, GitHub에 새 브랜치를 생성하여 랜드마크 예측 성능을 10px 미만으로 낮추고 CVM 분류 성능을 개선하기 위한 추가 개발을 진행하기로 결정.

### 17. `memo.txt` 복구 및 `README.md` 번역

- **`memo.txt` 복구:** 이전 `write_file` 명령의 실수로 인해 `memo.txt` 내용이 손실되었던 것을 대화 기록을 바탕으로 재구성하여 복구함.
- **`README.md` 번역:** `README_original.md`의 내용을 한국어로 번역하여 `README.md` 파일로 저장함.

### 18. MRE 최적화를 위한 재훈련 준비 (새 브랜치) - featyre/mre-optimization 

- **새 브랜치 생성:** `feature/mre-optimization` 브랜치를 생성하고 전환함.
- **ResNet 백본 미세 조정 구현:** `train.py`에 다음 로직을 추가함.
    - `FINE_TUNE_EPOCH = 20` 설정: 20 에포크 이후에 백본 동결 해제.
    - `FINE_TUNE_LR_FACTOR = 0.1` 설정: 동결 해제 시 학습률을 10배 감소.
    - `model.unfreeze()` 호출 및 옵티마이저, 스케줄러 재초기화 로직 추가.
- **에포크 증가:** `train.py`의 `EPOCHS`를 100에서 200으로 증가.
- **체크포인트 삭제:** 새로운 훈련을 위해 기존 체크포인트 파일들을 Windows `del /s /q` 명령을 사용하여 모두 삭제함.
- **훈련 시작:** `train.py` 실행을 시도했으나, 사용자 요청으로 취소됨. (사용자가 직접 터미널에서 실행하기로 함)

### 19. 홈(Home) 개발 환경 설정 및 GPU 가속 활성화

- **문제 진단 (1 - `scikit-learn` 누락):** `train.py` 실행 시 `ModuleNotFoundError` 발생. `scikit-learn` 라이브러리가 누락된 것을 확인하고 `pip`로 설치하여 해결.
- **문제 진단 (2 - GPU 미사용):** 사용자가 훈련 시 CPU만 사용된다고 보고함. `torch.cuda.is_available()` 확인 결과, CPU 전용 PyTorch가 설치된 것을 파악함.
- **코드 분석 및 해결책 제시:** 사용자가 직장(CPU)과 집(GPU) 환경을 위해 `train.py` 파일 분리를 고려했으나, 코드 분석 결과 이미 `DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'` 로직이 구현되어 있음을 확인. 코드 수정 없이, 환경에 맞는 PyTorch를 설치하는 것이 올바른 해결책임을 설명함.
- **PyTorch 재설치:** 기존의 CPU 전용 PyTorch를 삭제하고, 사용자의 `NVIDIA GeForce RTX 4060 Laptop GPU`에 맞는 CUDA 12.1 지원 PyTorch 버전을 재설치함.
- **설치 확인 및 훈련 인계:** 재설치 후 `torch.cuda.is_available()`가 `True`를 반환하고 GPU를 정상적으로 인식하는 것을 확인함. 이후 사용자가 직접 터미널에서 훈련을 시작하도록 안내하고 작업을 마무리지음.

### 20. GPU 사용률 최적화를 위한 데이터 로딩 파이프라인 개선

- **문제 진단:** 사용자가 훈련 중 GPU 사용률이 17%로 낮은 현상을 보고함. 코드 분석 결과, `DataLoader`가 병렬 데이터 로딩(`num_workers`) 및 메모리 고정(`pin_memory`) 옵션 없이 실행되어 데이터 로딩 과정에서 병목 현상이 발생하는 것을 확인함.
- **`train.py` 수정:**
    1.  `config.py`로부터 `NUM_WORKERS`, `PIN_MEMORY`, `VALID_BATCH_SIZE` 설정을 가져오도록 `import` 구문을 수정함.
    2.  훈련 및 검증 `DataLoader` 생성 시, `num_workers`와 `pin_memory=True` 옵션을 추가하여 CPU가 데이터를 미리, 그리고 병렬로 준비하게 함으로써 GPU가 대기하는 시간을 최소화함.
    3.  검증 `DataLoader`에 `config.py`에 정의된 `VALID_BATCH_SIZE`를 적용하여 일관성을 맞춤.
- **기대 효과:** 위 수정을 통해 데이터 로딩 병목 현상을 해결하고, GPU 사용률을 크게 향상시켜 전체적인 훈련 속도를 개선함.

### 21. `config.py` 및 `visualize.py` 버그 수정

- **`ImportError` 해결:** `train.py`에서 `VALID_BATCH_SIZE` 등을 `config.py`에서 가져오도록 수정한 후, `config.py`에 해당 변수들을 추가하는 것을 누락하여 `ImportError`가 발생함. `config.py`에 `VALID_BATCH_SIZE`, `NUM_WORKERS`, `PIN_MEMORY`를 추가하여 문제를 해결함.
- **시각화 오류 진단 및 수정:** `evaluate.py`의 MRE 결과(약 25px)와 달리 `visualize.py`의 결과물에서 예측점이 이미지 밖으로 벗어나는 현상 발생. 분석 결과, `visualize.py` 내에서 데이터 전처리가 이중으로 적용되는 버그를 발견함. 중복되는 `model_transform` 호출을 제거하여 문제를 해결하고, 시각화 결과가 MRE 수치와 일치하도록 수정함.

### 22. MRE 3px 미만 달성을 위한 향후 개선 아이디어 논의

- **새로운 목표 설정:** 임상적으로 유의미한 성능을 위해, 랜드마크 예측 MRE를 3px 미만으로 개선하는 것을 새로운 목표로 설정함.
- **아이디어 제시:** 목표 달성을 위해 다음과 같은 세 가지 주요 개선 방안을 논의함.
    1.  **모델/해상도 강화 (난이도: 쉬움):** ResNet-18 대신 `ResNet-50` 등 더 강력한 백본 모델을 사용하고, 입력 이미지 해상도를 256x256에서 `512x512` 등으로 높여 모델이 더 미세한 특징을 학습하도록 함.
    2.  **고급 데이터 증강 (난이도: 중간):** `albumentations` 라이브러리를 활용하여 Elastic Deformation, 밝기/대비 조절 등 의료 영상에 효과적인 데이터 증강을 추가하여 모델의 강인함과 일반화 성능을 높임.
    3.  **히트맵(Heatmap) 기반 접근법 (난이도: 어려움):** 현재의 직접 좌표 회귀 방식 대신, 랜드마크 탐지 분야의 표준적인 접근법인 히트맵 예측 방식으로 모델 아키텍처를 근본적으로 변경함. 정확도 향상에 가장 효과적일 것으로 기대되나, 코드 전반에 걸친 수정이 필요한 가장 큰 작업.

### 23-1. 아이디어 1 (ResNet-50) 적용 및 기존 모델 백업

- **기존 모델 최종 성능 기록:** 사용자가 ResNet-18 모델의 최종 최고 성능이 184 에포크에서 달성되었으며, MRE 18.3590, CVM 정확도 0.4357임을 확인함.
- **아이디어 1 구현:** MRE 3px 미만 달성을 위해 첫 번째 아이디어를 적용함.
    1. `config.py`의 `IMAGE_SIZE`를 `(512, 512)`로, `VALID_BATCH_SIZE`를 16으로 수정.
    2. `train.py`의 `BATCH_SIZE`를 8로 수정하여 GPU 메모리 부족에 대비.
    3. `model.py`의 백본을 `ResNet-18`에서 `ResNet-50`으로 교체하고, 512x512 입력에 맞는 `fc_input_size` (524288)를 재계산하여 적용.
- **기존 모델 백업:** 새로운 훈련과의 충돌을 막기 위해, 기존 `best_model.pth` 파일의 이름을 최종 MRE 값을 반영한 `resnet18_256x256_mre18.4.pth`로 변경하여 백업함.
- **체크포인트 정리:** 이름이 변경된 모델을 제외한 나머지 `checkpoints` 폴더를 삭제하여 호환성 문제를 방지함.
- **Git 추적 설정:** 백업된 모델 파일(`resnet18_256x256_mre18.4.pth`)이 커밋에 포함되도록 `.gitignore`에 예외 규칙을 추가함.

### 23-2. 아이디어 1 (ResNet-50) 훈련 결과 및 평가

- **훈련 실행:** `feature/resnet50-512px` 브랜치에서 ResNet-50 백본과 512x512 해상도로 모델 훈련을 약 100 에포크 동안 진행함.
- **최종 성능:** 98 에포크에서 최고 성능을 기록했으며, 결과는 다음과 같음.
    - Landmark MRE (px): 17.2830
    - CVM Accuracy: 0.4357
    - CVM F1-Score: 0.2190
- **결과 분석:** 기존 ResNet-18 모델(MRE 18.4px) 대비 성능이 소폭 향상되었으나, 목표치인 3px 미만에는 크게 미치지 못함. 현재의 직접 좌표 회귀 방식의 한계로 판단됨.
- **향후 계획:** 단순히 훈련을 더 진행하기보다는, 더 큰 성능 향상을 위해 아이디어 2(고급 데이터 증강) 또는 아이디어 3(히트맵)으로 전환하기로 결정함.

### 24-1 아이디어 2 (고급 데이터 증강) 적용 및 유틸리티 스크립트 리팩토링

- **데이터 증강 파이프라인 구축:**
  - `feature/albumentations` 브랜치에서 `albumentations` 라이브러리 기반의 데이터 증강 파이프라인을 `dataset.py`에 구현함.
  - `Affine` (이동, 스케일, 회전), `RandomBrightnessContrast`, `GaussNoise` 등의 변환을 적용함.
  - `torchvision` 기반의 기존 변환 코드를 제거하여 프로젝트 코드의 일관성을 확보함.

- **데이터 로더 오류 디버깅:**
  - 증강 적용 시 랜드마크 개수가 변하는 `RuntimeError` 발생.
  - 원인 분석 결과, `ElasticTransform`이 `remove_invisible=False` 설정을 따르지 않는 문제로 확인됨.
  - 안정적인 훈련을 위해 문제가 되는 `ElasticTransform`을 비활성화 조치함.

- **의존성 관리 개선:**
  - `requirements.txt`에 `torch`, `torchvision`, `scikit-learn`, `numpy` 등 누락된 주요 라이브러리를 추가함.
  - 의존성 격리를 위해 가상 환경(`venv`) 사용을 권장함.

- **평가 스크립트 리팩토링:**
  - `evaluate.py`와 `visualize.py`의 기능을 하나로 통합하여 `evaluate.py`로 단일화함.
  - 새로운 `evaluate.py`는 전체 테스트셋 평가와 더불어, `--visualize-index` 인자를 통해 특정 이미지의 예측 결과 시각화 기능을 선택적으로 수행할 수 있음.
  - 중복되는 `visualize.py` 파일은 삭제함.

### 24-2. F1 점수 및 정확도(Accuracy)의 의미와 신뢰도 기준

- **정확도(Accuracy)의 한계:** 가장 직관적이지만, 데이터 불균형(예: 특정 CVM 단계가 대부분인 경우)이 있을 때 모델의 실제 성능을 왜곡할 수 있음. 예를 들어, 모델이 항상 가장 흔한 클래스만 예측해도 정확도는 높게 나올 수 있음.

- **F1 점수(F1-Score)의 중요성:** 정밀도(Precision)와 재현율(Recall)의 조화 평균으로, 모든 클래스를 얼마나 균형 있게 잘 예측하는지 종합적으로 보여줌. 특히, 데이터 불균형 상황에서 소수 클래스에 대한 성능까지 측정하므로 모델의 실제 성능을 더 잘 대변함.

- **신뢰도 판단 기준 (CVM 분류 문제의 경우):**
  - **최소 기준:** 6개 클래스이므로 무작위 추측(약 16.7%)보다는 월등히 높아야 함.
  - **일반적 기준:** F1 점수 0.7 이상은 '양호', 0.9 이상은 '매우 뛰어남'으로 평가될 수 있음.
  - **가장 중요한 기준 (의료 분야):** '전문가 간 신뢰도' (여러 의사가 동일한 데이터를 얼마나 일치하게 진단하는지)가 AI 모델 성능의 최종 목표치가 됨. 관련 연구들에서 제시하는 F1 점수(보통 0.8 ~ 0.9 이상)를 달성해야 임상적으로 신뢰할 수 있다고 볼 수 있음.

### 24-3. 아이디어 2-1 (CVM 단독 학습) 실험 및 분석

- **실험 목표:** 멀티태스킹이 CVM 분류 성능 저하의 원인인지 확인하기 위해, CVM 분류 작업만 단독으로 학습하는 베이스라인 실험을 진행함.

- **구현:**
  - `model_cvm_only.py`: ResNet-18 백본과 CVM 분류 헤드 하나만으로 구성된 단순화된 모델을 새로 정의함.
  - `train_cvm_only.py`: CVM 단독 학습을 위한 전용 훈련 스크립트를 작성함. Early Stopping, LR Scheduler 등은 검증 손실을 기준으로 작동하도록 수정.
  - `dataset.py` 리팩토링: 다양한 이미지 크기(224x224 등)를 지원할 수 있도록 `image_size`를 인자로 받게 수정하고, 이를 사용하는 모든 스크립트(`train.py`, `evaluate.py` 등)를 업데이트함.

- **실험 결과:**
  - CVM 단독 학습 결과, F1 점수가 약 0.1~0.2 범위에서 정체되며 **학습에 완전히 실패함.**

- **결론 및 향후 계획:**
  - **문제의 근본 원인이 멀티태스킹이 아님을 확인함.** 모델이 두개골 전체 이미지로부터 CVM 단계 구분에 필요한 미세한 특징을 학습하지 못하는 것으로 판단됨.
  - 이에 따라, `ToDo.txt`의 `C12` 항목인 **ROI(관심 영역) 기반 파이프라인**을 다음 단계로 추진하기로 결정함. (경추 영역만 잘라내어 분류기에 학습시키는 방식)
