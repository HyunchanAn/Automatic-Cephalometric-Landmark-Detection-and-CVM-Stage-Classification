## 프로젝트 재현 및 AI 모델 훈련 환경 구축 기록

Original project: https://github.com/manwaarkhd/aariz

### 1. 프로젝트 분석
- `README.md`와 소스 코드를 분석하여, 이 프로젝트가 'Aariz'라는 두부 계측 방사선 사진 데이터셋을 제공하는 것이 주 목적임을 파악했습니다.
- `dataset.py`를 통해 데이터셋의 기본적인 로드 방법을 확인했습니다.

### 2. 데이터셋 확보 및 준비
- 웹 검색을 통해 Figshare에 공유된 데이터셋의 다운로드 링크를 찾아냈습니다.
- 사용자가 `Aariz` 폴더에 데이터셋을 준비했고, 폴더 내 `readme.txt`를 읽어 데이터의 상세 구조를 파악했습니다.

### 3. 데이터 로딩 및 디버깅
- `dataset.py`를 사용하여 데이터 로드를 시도했으나, 라이브러리 누락 (`numpy`, `opencv-python`) 및 오래된 코드 (`np.float`)로 인해 오류가 발생했습니다.
- 필요한 라이브러리를 설치하고, `np.float`를 `np.float64`로 수정하여 모든 오류를 해결했습니다.
- 최종적으로 데이터셋의 첫 번째 샘플(이미지, 랜드마크, CVM 단계)을 성공적으로 불러오는 데 성공했습니다.

### 4. AI 모델 훈련 환경 구축
- 사용자의 요청에 따라, PyTorch 기반의 AI 모델 훈련 환경 구성을 시작했습니다.
- `torch`, `torchvision` 라이브러리를 설치했습니다.
- `dataset.py`를 PyTorch의 `DataLoader`와 호환되도록 수정했습니다.
- `model.py` 파일을 새로 생성하고, 랜드마크 예측과 CVM 분류를 위한 두 개의 출력 헤드를 가진 기본 CNN 모델(`CephNet`)의 뼈대를 정의했습니다.
- `train.py` 파일을 새로 생성하고, 데이터 로딩, 모델 초기화, 손실 함수, 옵티마이저 설정 및 기본적인 훈련 루프를 포함한 전체 훈련 프로세스를 구현했습니다.

### 5. 최종 설정
- `train.py`의 이미지 크기(256x256)에 맞춰 `model.py`의 `fc_input_size` 변수의 정확한 값을 계산했습니다.
- 계산된 값(`65536`)으로 `model.py`를 업데이트하여, 모델이 훈련을 시작할 수 있도록 최종 준비를 마쳤습니다.

### 6. 모델 생성 및 저장 (.pth 파일)
- `train.py` 스크립트를 실행하여 `CephNet` 모델의 훈련을 진행했습니다.
- 훈련이 완료된 후, 모델의 학습된 가중치(weights)를 `cephnet_model.pth` 파일로 저장했습니다.

### 7. 추가 훈련 및 모델 활용
- **추가 훈련:** `train.py` 파일의 `EPOCHS` 값을 원하는 만큼 늘린 후, 터미널에서 `python train.py`를 다시 실행하면 마지막으로 저장된 상태에서 훈련을 이어서 계속할 수 있습니다. (참고: 10번 항목에 구현된 체크포인트 기능 덕분에, 이제 훈련이 중단되어도 자동으로 마지막 지점부터 재개됩니다.)
- **저장된 모델 불러오기:** 저장된 `cephnet_model.pth` 파일을 사용하여 예측이나 추가 훈련을 하려면, 다음과 같은 코드를 사용합니다.

```python
import torch
from model import AdvancedCephNet # 모델이 변경되었으므로 AdvancedCephNet을 사용

# 1. 모델 구조를 먼저 정의합니다.
model = AdvancedCephNet()

# 2. 저장된 가중치를 불러와 모델에 적용합니다.
# 가장 마지막 에포크의 체크포인트 파일을 사용하면 됩니다.
checkpoint = torch.load('checkpoints/checkpoint_epoch_4.pth') # 예시: 4번째 에포크
model.load_state_dict(checkpoint['model_state_dict'])

# 3. 모델을 평가 모드로 설정합니다. (예측에 사용하는 경우)
model.eval()

# 이제 `model` 변수를 사용하여 예측 등을 수행할 수 있습니다.
```

### 8. 모델 성능 향상 (데이터 증강 및 검증)
- **개념:** 모델의 일반화 성능을 높이고 과적합을 방지하기 위해, 훈련 데이터에 인위적인 변화를 주어 데이터의 양을 늘리는 기법입니다.
- **구현:** `train.py`의 훈련 데이터 로더에 `RandomHorizontalFlip` (무작위 좌우 반전)과 `RandomRotation` (무작위 회전) 변환을 추가했습니다. 이 변환들은 훈련 시에만 적용되며, 모델이 다양한 각도와 방향의 이미지에 대응할 수 있도록 학습시킵니다.
- **검증 추가:** 매 에포크 훈련이 끝날 때마다, 데이터 증강을 적용하지 않은 별도의 '검증 데이터셋(validation dataset)'으로 모델의 성능을 평가하는 로직을 추가했습니다. 훈련 손실(Train Loss)과 함께 검증 손실(Validation Loss)이 출력되며, 이 검증 손실값을 통해 모델의 실제 성능과 과적합 여부를 더 객관적으로 파악할 수 있습니다.
- **사용법:** 사용법은 이전과 동일합니다. 터미널에서 `python train.py`를 실행하면 데이터 증강이 적용된 훈련과 검증이 함께 진행됩니다.

### 9. 추가 작업 및 오류 수정
- **검증 데이터셋 부재:** 훈련 스크립트 실행 중, `Aariz` 폴더 내에 `valid` 폴더가 없어 발생하는 `FileNotFoundError`를 확인했습니다.
- **경로 처리 로직 수정:** `dataset.py`에서 데이터셋 모드(`TRAIN`, `VALID`, `TEST`)를 처리할 때, 폴더명과 일치하도록 `capitalize()`(첫 글자만 대문자) 대신 `lower()`(모두 소문자)를 사용하도록 코드를 수정하여 향후 발생할 수 있는 경로 문제를 예방했습니다.
- **검증 데이터셋 생성:** `train` 데이터셋의 일부를 사용하여 `valid` 데이터셋을 생성하기로 결정하고, `Aariz/valid` 경로와 그 하위 폴더(Cephalograms, Annotations 등)를 생성했습니다. 그 후, `split_dataset.py` 스크립트를 작성하여 `train` 데이터셋의 20%를 `valid` 폴더로 이동시켜 검증 데이터셋 구축을 완료했습니다.

### 10. 훈련 이어하기 기능 구현 (체크포인팅)
- **목표:** 훈련이 중단되었을 때, 처음부터 다시 시작하는 대신 마지막으로 저장된 지점부터 이어서 훈련을 재개할 수 있도록 합니다.
- **`config.py` 수정:** 체크포인트 파일들을 저장할 경로를 `CHECKPOINT_PATH = "checkpoints"` 변수로 추가했습니다.
- **`train.py` 수정:**
    1.  **체크포인트 로드:** 훈련 시작 시, `CHECKPOINT_PATH`에 저장된 체크포인트가 있는지 확인합니다. 가장 최근 에포크의 체크포인트 파일을 찾아 모델의 가중치(`model_state_dict`)와 옵티마이저 상태(`optimizer_state_dict`)를 불러온 후, 다음 에포크부터 훈련을 시작합니다.
    2.  **체크포인트 저장:** 매 에포크의 훈련 및 검증이 끝난 후, 현재 에포크 번호, 모델 가중치, 옵티마이저 상태를 `checkpoint_epoch_{에포크번호}.pth` 형식의 파일로 `CHECKPOINT_PATH`에 저장합니다.
- **사용법:** 이전과 동일하게 터미널에서 `python train.py`를 실행하면 됩니다. `checkpoints` 폴더에 저장된 파일이 있으면 자동으로 불러와 훈련을 재개하고, 없으면 처음부터 훈련을 시작합니다.

### 11. 모델 성능 평가 지표 추가
- **목표:** 손실(Loss) 값 외에 더 직관적인 지표를 통해 모델의 성능을 다각도로 평가합니다.
- **`scikit-learn` 설치:** 분류 모델의 성능 지표를 손쉽게 계산하기 위해 `pip install scikit-learn` 명령어로 라이브러리를 설치했습니다.
- **`train.py` 수정:**
    1.  **지표 계산 로직 추가:** 검증(validation) 단계에서, 매 에포크가 끝날 때마다 아래의 지표들을 새로 계산하도록 로직을 추가했습니다.
        - **랜드마크 예측:** 평균 반경 오차(Mean Radial Error, MRE)를 계산하여, 예측된 랜드마크가 실제 위치에서 평균적으로 몇 픽셀 벗어나는지 측정합니다.
        - **CVM 분류:** `scikit-learn`을 사용하여 정확도(Accuracy)와 F1-점수(F1-Score)를 계산합니다.
    2.  **결과 출력 형식 변경:** 에포크마다 출력되는 결과를 더 명확하게 볼 수 있도록 형식을 변경하고, 새로 추가된 모든 성능 지표(`Landmark MRE (px)`, `CVM Accuracy`, `CVM F1-Score`)를 함께 보여주도록 수정했습니다.

### 12. 전이 학습(Transfer Learning) 도입
- **목표:** 더 깊고 성능이 검증된 모델을 사용하여 성능을 향상시킵니다.
- **`model.py` 수정:**
    1. **`AdvancedCephNet` 추가:** `torchvision`에서 제공하는 사전 훈련된 `ResNet-18` 모델을 기반으로 하는 `AdvancedCephNet` 클래스를 새로 정의했습니다.
    2. **가중치 고정(Freezing):** 모델의 특징 추출기 역할을 하는 ResNet 부분의 파라미터를 모두 '얼려서'(`requires_grad=False`), 사전 훈련된 가중치가 훈련 초기에 손상되지 않도록 보호했습니다. 이로써 훈련 시에는 새로 추가된 출력 헤드 부분만 학습됩니다.
    3. **`unfreeze` 메소드 추가:** 추후 전체 모델을 미세 조정(fine-tuning)할 때, '얼려둔' ResNet 파라미터를 다시 학습 가능하도록 만드는 `unfreeze()` 메소드를 모델 내에 추가했습니다.
- **`train.py` 수정:** 훈련 스크립트에서 사용하는 모델을 기존 `CephNet`에서 새로운 `AdvancedCephNet`으로 교체했습니다.
- **참고사항:** 모델 구조가 완전히 변경되었기 때문에, 기존에 `CephNet`으로 훈련하며 저장했던 체크포인트는 더 이상 호환되지 않습니다. 따라서 `checkpoints` 폴더를 삭제하여 새로운 모델로 훈련을 처음부터 다시 시작했습니다.

### 13. 학습률 스케줄러 및 최고 성능 모델 저장 기능 추가
- **목표:** 훈련 효율성을 높이고, 과적합을 방지하며, 가장 좋은 성능을 보인 모델을 자동으로 저장합니다.
- **`train.py` 수정:**
    1.  **학습률 스케줄러 (`ReduceLROnPlateau`) 도입:**
        - `torch.optim.lr_scheduler.ReduceLROnPlateau`를 사용하여 검증 MRE가 `LR_SCHEDULER_PATIENCE` (5) 에포크 동안 개선되지 않으면 학습률을 `LR_SCHEDULER_FACTOR` (0.1)만큼 감소시킵니다. 이는 모델이 최적점에 더 잘 수렴하도록 돕습니다.
        - `min_lr`을 설정하여 학습률이 너무 낮아지는 것을 방지합니다.
    2.  **최고 성능 모델 저장 (`best_model.pth`) 구현:**
        - 검증 MRE를 기준으로 가장 좋은 성능을 보인 모델의 가중치(`state_dict`)를 `checkpoints` 폴더 내에 `best_model.pth` 파일로 별도 저장합니다.
        - 훈련 재개 시, `best_mre`와 `best_epoch` 값도 함께 불러와서 최고 성능 모델 저장 로직이 올바르게 작동하도록 합니다.
- **훈련 결과:** 50 에포크 훈련 결과, 랜드마크 MRE가 초기 1608.8691px에서 최종 908.8891px로 크게 감소하여 모델의 학습이 성공적으로 진행되었음을 확인했습니다.

### 14. 테스트 데이터셋으로 최종 평가
- **목표:** 훈련 및 검증 과정에서 사용되지 않은 독립적인 테스트 데이터셋을 사용하여 모델의 최종 성능을 객관적으로 평가합니다.
- **`evaluate.py` 스크립트 생성:**
    1.  **모델 로드:** 훈련 중 가장 좋은 성능을 보인 `best_model.pth` 파일을 불러와 모델을 초기화합니다.
    2.  **테스트 데이터셋 로드:** `AarizDataset`을 `mode="TEST"`로 설정하여 테스트 데이터셋을 불러옵니다.
    3.  **성능 지표 계산:** 테스트 데이터셋 전체에 대해 모델을 실행하고, 훈련 및 검증 단계에서 사용했던 동일한 성능 지표(랜드마크 MRE, CVM 정확도, CVM F1-점수)를 계산합니다.
    4.  **결과 출력:** 계산된 최종 성능 지표를 콘솔에 출력합니다.
- **평가 결과:**
    - **Landmark MRE (px): 711.1362**
    - **CVM Accuracy: 0.4133**
    - **CVM F1-Score: 0.2041**
    테스트 세트의 랜드마크 MRE가 검증 세트의 최고 MRE(908.8891px)보다 더 낮게 측정되어, 모델이 새로운 데이터에 대해서도 우수한 일반화 성능을 보임을 확인했습니다.

### 15. 랜드마크 스케일링 문제 해결 및 모델 재훈련 준비

- **문제 진단:** `visualize.py` 실행 시 랜드마크가 이미지 범위 밖에 그려지는 문제 발생. 디버그 출력 결과, 모델이 예측하는 랜드마크 좌표가 원본 이미지 크기(예: 1972x2225)를 훨씬 초과하는 값으로 나타남. 이는 `dataset.py`에서 이미지를 `IMAGE_SIZE`(예: 256x256)로 리사이즈할 때, 랜드마크 좌표는 리사이즈하지 않아 발생한 불일치 문제로 파악됨.
- **`dataset.py` 수정:** `__getitem__` 함수 내에서 `self.transform`이 적용될 때, 랜드마크 좌표도 `IMAGE_SIZE`에 맞춰 비례적으로 스케일링되도록 로직을 추가함.
- **`visualize.py` 수정:**
    - `AarizDataset` 초기화 시 `model_transform`을 전달하도록 수정.
    - 랜드마크 시각화 시, `landmarks_true`와 `landmarks_pred` 모두 `IMAGE_SIZE` 기반 좌표를 원본 이미지 크기로 다시 스케일링하여 그리도록 로직을 수정.
    - 랜드마크 가시성 향상을 위해 원의 `radius`를 5에서 10으로, 선의 `thickness`를 1에서 3으로 증가.
    - 디버그 출력문 제거.
- **재훈련 결정:** 랜드마크 예측 성능 향상 및 MRE 10px 이내 목표 달성을 위해, 올바르게 스케일링된 랜드마크 타겟으로 모델을 처음부터 재훈련하기로 결정.
- **`train.py` 수정:** `EPOCHS`를 50에서 100으로 증가.
- **체크포인트 삭제 준비:** 새로운 훈련을 위해 기존 체크포인트 파일들을 삭제할 예정이었으나, 사용자 요청으로 보류됨.

### 16. 모델 재훈련 결과 및 향후 계획

- **`train.py` 재실행:** `dataset.py` 및 `visualize.py`의 랜드마크 스케일링 로직 수정 후, `EPOCHS=100`으로 설정하여 모델을 처음부터 재훈련.
- **최종 훈련 결과 (Epoch 82에서 Best Model 달성):
    - Landmark MRE (px): 17.4700
    - CVM Accuracy: 0.4500
    - CVM F1-Score: 0.2248
- **평가:**
    - **랜드마크 예측:** 이전 MRE 527px 대비 17.47px로 크게 향상. 임상적 유용성 여부는 추가적인 논의가 필요하나, 10px 목표에 근접한 강력한 결과.
    - **CVM 분류:** Accuracy 0.4500, F1-Score 0.2248로 여전히 매우 낮은 성능을 보이며, 임상적으로 사용하기 부적합.
- **향후 계획:** 현재 상태를 기록하고, GitHub에 새 브랜치를 생성하여 랜드마크 예측 성능을 10px 미만으로 낮추고 CVM 분류 성능을 개선하기 위한 추가 개발을 진행하기로 결정.