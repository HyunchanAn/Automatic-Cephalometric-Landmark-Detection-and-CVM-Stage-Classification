## 프로젝트 재현 및 AI 모델 훈련 환경 구축 기록

Original project: https://github.com/manwaarkhd/aariz

##### 2025.09.15 (1일차) 병원 #####

### 1. 데이터셋 확보 및 준비
- Figshare에 공유된 데이터셋의 다운로드 링크 확보 (https://figshare.com/articles/dataset/Aariz_Cephalometric_Dataset/27986417?file=51041642)
- `Aariz` 폴더에 데이터셋 준비, 폴더 내 `readme.txt`를 읽어 데이터의 상세 구조를 파악

### 2. 데이터 로딩 및 디버깅
- `dataset.py`를 사용하여 데이터 로드를 시도했으나, 라이브러리 누락 (`numpy`, `opencv-python`) 및 오래된 코드 (`np.float`)로 인해 오류 발생
- 필요한 라이브러리를 설치하고, `np.float`를 `np.float64`로 수정하여 모든 오류 해결
- 최종적으로 데이터셋의 첫 번째 샘플(이미지, 랜드마크, CVM 단계)을 성공적으로 로딩함

### 3. AI 모델 훈련 환경 구축
- PyTorch 기반의 AI 모델 훈련 환경 구성 시작
- `torch`, `torchvision` 라이브러리 설치
- `dataset.py`를 PyTorch의 `DataLoader`와 호환되도록 수정
- `model.py` 파일을 새로 생성하고, 랜드마크 예측과 CVM 분류를 위한 두 개의 출력 헤드를 가진 기본 CNN 모델(`CephNet`) 골격 정의
- `train.py` 파일을 새로 생성하고, 데이터 로딩, 모델 초기화, 손실 함수, 옵티마이저 설정 및 기본적인 훈련 루프를 포함한 전체 훈련 프로세스 구현

### 4. 최종 설정
- `train.py`의 이미지 크기(256x256)에 맞춰 `model.py`의 `fc_input_size` 변수의 정확한 값 계산
- 계산된 값(`65536`)으로 `model.py`를 업데이트하여, 모델이 훈련을 시작할 수 있도록 최종 준비

### 5. 모델 생성 및 저장 (.pth 파일)
- `train.py` 스크립트를 실행하여 `CephNet` 모델의 훈련 진행
- 훈련이 완료된 후, 모델의 학습된 가중치(weights)를 `cephnet_model.pth` 로 저장

### 6. 추가 훈련 및 모델 활용
- 추가 훈련: `train.py` 파일의 `EPOCHS` 값을 원하는 만큼 늘린 후, 터미널에서 `python train.py`를 다시 실행하면 마지막으로 저장된 상태에서 훈련을 이어서 계속할 수 있게 함. (참고: #9 항목에 구현된 체크포인트 기능 덕분에, 이제 훈련이 중단되어도 자동으로 마지막 지점부터 재개됩니다.)

##### 2025.09.16 (2일차) 병원 #####

### 7. 모델 성능 향상 (데이터 증강 및 검증)
- 개념: 모델의 일반화 성능을 높이고 과적합을 방지하기 위해, 훈련 데이터에 인위적인 변화를 주어 데이터의 양을 늘리는 기법 적용
- 구현: `train.py`의 훈련 데이터 로더에 `RandomHorizontalFlip` (무작위 좌우 반전)과 `RandomRotation` (무작위 회전) 변환을 추가했습니다. 이 변환들은 훈련 시에만 적용되며, 모델이 다양한 각도와 방향의 이미지에 대응할 수 있도록 학습
- 검증 추가: 매 에포크 훈련이 끝날 때마다, 데이터 증강을 적용하지 않은 별도의 '검증 데이터셋(validation dataset)'으로 모델의 성능을 평가하는 로직을 추가했습니다. 훈련 손실(Train Loss)과 함께 검증 손실(Validation Loss)이 출력되며, 이 검증 손실값을 통해 모델의 실제 성능과 과적합 여부를 더 객관적으로 파악 가능
- 사용법: 이전과 동일 - 터미널에서 `python train.py`를 실행하면 데이터 증강이 적용된 훈련과 검증이 함께 진행

### 8. 추가 작업 및 오류 수정
- 검증 데이터셋 부재: 훈련 스크립트 실행 중, `Aariz` 폴더 내에 `valid` 폴더가 없어 발생하는 `FileNotFoundError`를 확인
- 경로 처리 로직 수정: `dataset.py`에서 데이터셋 모드(`TRAIN`, `VALID`, `TEST`)를 처리할 때, 폴더명과 일치하도록 `capitalize()`(첫 글자만 대문자) 대신 `lower()`(모두 소문자)를 사용하도록 코드를 수정하여 향후 발생할 수 있는 경로 문제를 예방
- 검증 데이터셋 생성: `train` 데이터셋의 일부를 사용하여 `valid` 데이터셋을 생성하기로 결정하고, `Aariz/valid` 경로와 그 하위 폴더(Cephalograms, Annotations 등)를 생성했습니다. 그 후, `split_dataset.py` 스크립트를 작성하여 `train` 데이터셋의 20%를 `valid` 폴더로 이동시켜 검증 데이터셋 구축 완료

### 9. 훈련 이어하기 기능 구현 (체크포인팅)
- 목표: 훈련이 중단되었을 때, 처음부터 다시 시작하는 대신 마지막으로 저장된 지점부터 이어서 훈련을 재개할 수 있도록 함
- `config.py` 수정: 체크포인트 파일들을 저장할 경로를 `CHECKPOINT_PATH = "checkpoints"` 변수로 추가
- `train.py` 수정:
    1.  체크포인트 로드: 훈련 시작 시, `CHECKPOINT_PATH`에 저장된 체크포인트가 있는지 확인, 이후 가장 최근 에포크의 체크포인트 파일을 찾아 모델의 가중치(`model_state_dict`)와 옵티마이저 상태(`optimizer_state_dict`)를 불러온 후, 다음 에포크부터 훈련을 시작
    2.  체크포인트 저장: 매 에포크의 훈련 및 검증이 끝난 후, 현재 에포크 번호, 모델 가중치, 옵티마이저 상태를 `checkpoint_epoch_{에포크번호}.pth` 형식의 파일로 `CHECKPOINT_PATH`에 저장
- 사용법: 이전과 동일하게 터미널에서 `python train.py`를 실행 - `checkpoints` 폴더에 저장된 파일이 있으면 자동으로 불러와 훈련을 재개하고, 없으면 처음부터 훈련을 시작

### 10. 모델 성능 평가 지표 추가
- 목표: 손실(Loss) 값 외에 더 직관적인 지표를 통해 모델의 성능을 다각도로 평가 
- `scikit-learn` 설치: 분류 모델의 성능 지표의 계산
- `train.py` 수정:
    1.  지표 계산 로직 추가: 검증(validation) 단계에서, 매 에포크가 끝날 때마다 아래의 지표들을 새로 계산하도록 로직 추가
        - 랜드마크 예측: 평균 반경 오차(Mean Radial Error, MRE)를 계산하여, 예측된 랜드마크가 실제 위치에서 평균적으로 몇 픽셀 벗어나는지 측정
        - CVM 분류: `scikit-learn`을 사용하여 정확도(Accuracy)와 F1-점수(F1-Score) 계산
    2.  결과 출력 형식 변경: 에포크마다 출력되는 결과를 더 명확하게 볼 수 있도록 형식을 변경하고, 새로 추가된 모든 성능 지표(`Landmark MRE (px)`, `CVM Accuracy`, `CVM F1-Score`)를 함께 보여주도록 수정

##### 2025.09.18 (3일차) 병원 #####

### 11. 전이 학습(Transfer Learning) 도입
- 목표: 더 깊고 성능이 검증된 모델을 사용하여 성능을 향상
- `model.py` 수정:
    1. `AdvancedCephNet` 추가: `torchvision`에서 제공하는 사전 훈련된 `ResNet-18` 모델을 기반으로 하는 `AdvancedCephNet` 클래스를 새로 정의
    2. 가중치 고정(Freezing): 모델의 특징 추출기 역할을 하는 ResNet 부분의 파라미터를 모두 '얼려서'(`requires_grad=False`), 사전 훈련된 가중치가 훈련 초기에 손상되지 않도록 보호 - 이로써 훈련 시에는 새로 추가된 출력 헤드 부분만 학습함
    3. `unfreeze` 메소드 추가: 추후 전체 모델을 미세 조정(fine-tuning)할 때, '얼려둔' ResNet 파라미터를 다시 학습 가능하도록 만드는 `unfreeze()` 메소드를 모델 내에 추가
- `train.py` 수정: 훈련 스크립트에서 사용하는 모델을 기존 `CephNet`에서 새로운 `AdvancedCephNet`으로 교체
- 참고사항: 모델 구조가 완전히 변경되었기 때문에, 기존에 `CephNet`으로 훈련하며 저장했던 체크포인트는 더 이상 호환되지 않음 - 따라서 `checkpoints` 폴더를 삭제하여 새로운 모델로 훈련을 처음부터 다시 시작

### 12. 학습률 스케줄러 및 최고 성능 모델 저장 기능 추가
- 목표: 훈련 효율성을 높이고, 과적합을 방지하며, 가장 좋은 성능을 보인 모델을 자동으로 저장
- `train.py` 수정:
    1.  학습률 스케줄러 (`ReduceLROnPlateau`) 도입:
        - `torch.optim.lr_scheduler.ReduceLROnPlateau`를 사용하여 검증 MRE가 `LR_SCHEDULER_PATIENCE` (5) 에포크 동안 개선되지 않으면 학습률을 `LR_SCHEDULER_FACTOR` (0.1)만큼 감소 - 이는 모델이 최적점에 더 잘 수렴하도록 보조
        - `min_lr`을 설정하여 학습률이 너무 낮아지는 것을 방지
    2.  최고 성능 모델 저장 (`best_model.pth`) 구현:
        - 검증 MRE를 기준으로 가장 좋은 성능을 보인 모델의 가중치(`state_dict`)를 `checkpoints` 폴더 내에 `best_model.pth` 파일로 별도 저장
        - 훈련 재개 시, `best_mre`와 `best_epoch` 값도 함께 불러와서 최고 성능 모델 저장 로직이 올바르게 작동하도록
- 훈련 결과: 50 에포크 훈련 결과, 랜드마크 MRE가 초기 1608.8691px에서 최종 908.8891px로 크게 감소하여 모델의 학습이 성공적으로 진행되었음을 확인

### 13. 테스트 데이터셋으로 최종 평가
- 목표: 훈련 및 검증 과정에서 사용되지 않은 독립적인 테스트 데이터셋을 사용하여 모델의 최종 성능을 객관적으로 평가
- `evaluate.py` 스크립트 생성:
    1.  모델 로드: 훈련 중 가장 좋은 성능을 보인 `best_model.pth` 파일을 불러와 모델 초기화
    2.  테스트 데이터셋 로드: `AarizDataset`을 `mode="TEST"`로 설정하여 테스트 데이터셋 로딩
    3.  성능 지표 계산: 테스트 데이터셋 전체에 대해 모델을 실행하고, 훈련 및 검증 단계에서 사용했던 동일한 성능 지표(랜드마크 MRE, CVM 정확도, CVM F1-점수) 계산
    4.  결과 출력: 계산된 최종 성능 지표를 콘솔에 출력
- 평가 결과:
    - Landmark MRE (px): 711.1362
    - CVM Accuracy: 0.4133
    - CVM F1-Score: 0.2041
    테스트 세트의 랜드마크 MRE가 검증 세트의 최고 MRE(908.8891px)보다 더 낮게 측정되어, 모델이 새로운 데이터에 대해서도 우수한 일반화 성능을 보임 확인

### 14. 랜드마크 스케일링 문제 해결 및 모델 재훈련 준비
- 문제 진단: `visualize.py` 실행 시 랜드마크가 이미지 범위 밖에 그려지는 문제 발생. 디버그 출력 결과, 모델이 예측하는 랜드마크 좌표가 원본 이미지 크기(예: 1972x2225)를 훨씬 초과하는 값으로 나타남. 이는 `dataset.py`에서 이미지를 `IMAGE_SIZE`(예: 256x256)로 리사이즈할 때, 랜드마크 좌표는 리사이즈하지 않아 발생한 불일치 문제로 파악됨.
- `dataset.py` 수정: `__getitem__` 함수 내에서 `self.transform`이 적용될 때, 랜드마크 좌표도 `IMAGE_SIZE`에 맞춰 비례적으로 스케일링되도록 로직을 추가함.
- `visualize.py` 수정:
    - `AarizDataset` 초기화 시 `model_transform`을 전달하도록 수정.
    - 랜드마크 시각화 시, `landmarks_true`와 `landmarks_pred` 모두 `IMAGE_SIZE` 기반 좌표를 원본 이미지 크기로 다시 스케일링하여 그리도록 로직을 수정.
    - 랜드마크 가시성 향상을 위해 원의 `radius`를 5에서 10으로, 선의 `thickness`를 1에서 3으로 증가.
    - 디버그 출력문 제거.
- 재훈련 결정: 랜드마크 예측 성능 향상 및 MRE 10px 이내 목표 달성을 위해, 올바르게 스케일링된 랜드마크 타겟으로 모델을 처음부터 재훈련하기로 결정.
- `train.py` 수정: `EPOCHS`를 50에서 100으로 증가.

### 15. 모델 재훈련 결과 및 향후 계획
- `train.py` 재실행: `dataset.py` 및 `visualize.py`의 랜드마크 스케일링 로직 수정 후, `EPOCHS=100`으로 설정하여 모델을 처음부터 재훈련.
- 최종 훈련 결과 (Epoch 82에서 Best Model 달성):
    - Landmark MRE (px): 17.4700
    - CVM Accuracy: 0.4500
    - CVM F1-Score: 0.2248
- 평가:
    - 랜드마크 예측: 이전 MRE 527px 대비 17.47px로 크게 향상. 임상적 유용성 여부는 추가적인 논의가 필요하나, 10px 목표에 근접한 강력한 결과.
    - CVM 분류: Accuracy 0.4500, F1-Score 0.2248로 여전히 매우 낮은 성능을 보이며, 임상적으로 사용하기 부적합.
- 향후 계획: 현재 상태를 기록하고, GitHub에 새 브랜치를 생성하여 랜드마크 예측 성능을 10px 미만으로 낮추고 CVM 분류 성능을 개선하기 위한 추가 개발을 진행하기로 결정.

### 16. `memo.txt` 복구 및 `README.md` 번역
- `memo.txt` 복구: 이전 `write_file` 명령의 실수로 인해 `memo.txt` 내용이 손실되었던 것을 대화 기록을 바탕으로 재구성하여 복구함.
- `README.md` 번역: `README_original.md`의 내용을 한국어로 번역하여 `README.md` 파일로 저장함.

##### 2025.09.19 (4일차) 병원 #####

### 17. MRE 최적화를 위한 재훈련 준비 (새 브랜치) - featyre/mre-optimization 
- 새 브랜치 생성: `feature/mre-optimization` 브랜치를 생성하고 전환함.
- ResNet 백본 미세 조정 구현: `train.py`에 다음 로직을 추가함.
    - `FINE_TUNE_EPOCH = 20` 설정: 20 에포크 이후에 백본 동결 해제.
    - `FINE_TUNE_LR_FACTOR = 0.1` 설정: 동결 해제 시 학습률을 10배 감소.
    - `model.unfreeze()` 호출 및 옵티마이저, 스케줄러 재초기화 로직 추가.
- 에포크 증가: `train.py`의 `EPOCHS`를 100에서 200으로 증가.
- 체크포인트 삭제: 새로운 훈련을 위해 기존 체크포인트 파일들을 모두 삭제함.

##### 2025.09.19 (4일차) 집 #####

### 18. 홈(Home) 개발 환경 설정 및 GPU 가속 활성화
- 문제 진단 (1 - `scikit-learn` 누락): `train.py` 실행 시 `ModuleNotFoundError` 발생. `scikit-learn` 라이브러리가 누락된 것을 확인하고 `pip`로 설치하여 해결.
- 문제 진단 (2 - GPU 미사용): 훈련 시 CPU만 사용된다고 보고함. `torch.cuda.is_available()` 확인 결과, CPU 전용 PyTorch가 설치된 것을 파악함.
- 코드 분석 및 해결책 제시: 직장(낮은성능)과 집(고성능) 환경을 위해 `train.py` 파일 분리를 고려했으나, 코드 분석 결과 이미 `DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'` 로직이 구현되어 있음을 확인. 코드 수정 없이, 환경에 맞는 PyTorch를 설치하는 것이 올바른 해결책임을 설명함.
- PyTorch 재설치: 기존의 CPU 전용 PyTorch를 삭제하고, 집에서 사용하는 환경 `NVIDIA GeForce RTX 4060 Laptop GPU`에 맞는 CUDA 12.1 지원 PyTorch 버전을 재설치함.
- 설치 확인 및 훈련 인계: 재설치 후 `torch.cuda.is_available()`가 `True`를 반환하고 GPU를 정상적으로 인식하는 것을 확인함. 

### 19. GPU 사용률 최적화를 위한 데이터 로딩 파이프라인 개선
- 문제 진단: 훈련 중 GPU 사용률이 17%로 낮은 현상 발견함. 코드 분석 결과, `DataLoader`가 병렬 데이터 로딩(`num_workers`) 및 메모리 고정(`pin_memory`) 옵션 없이 실행되어 데이터 로딩 과정에서 병목 현상이 발생하는 것을 확인함.
- `train.py` 수정:
    1.  `config.py`로부터 `NUM_WORKERS`, `PIN_MEMORY`, `VALID_BATCH_SIZE` 설정을 가져오도록 `import` 구문을 수정함.
    2.  훈련 및 검증 `DataLoader` 생성 시, `num_workers`와 `pin_memory=True` 옵션을 추가하여 CPU가 데이터를 미리, 그리고 병렬로 준비하게 함으로써 GPU가 대기하는 시간을 최소화함.
    3.  검증 `DataLoader`에 `config.py`에 정의된 `VALID_BATCH_SIZE`를 적용하여 일관성을 맞춤.
- 기대 효과: 위 수정을 통해 데이터 로딩 병목 현상을 해결하고, GPU 사용률을 크게 향상시켜 전체적인 훈련 속도를 개선함.

### 20. `config.py` 및 `visualize.py` 버그 수정
- `ImportError` 해결: `train.py`에서 `VALID_BATCH_SIZE` 등을 `config.py`에서 가져오도록 수정한 후, `config.py`에 해당 변수들을 추가하는 것을 누락하여 `ImportError`가 발생함. `config.py`에 `VALID_BATCH_SIZE`, `NUM_WORKERS`, `PIN_MEMORY`를 추가하여 문제를 해결함.
- 시각화 오류 진단 및 수정: `evaluate.py`의 MRE 결과(약 25px)와 달리 `visualize.py`의 결과물에서 예측점이 이미지 밖으로 벗어나는 현상 발생. 분석 결과, `visualize.py` 내에서 데이터 전처리가 이중으로 적용되는 버그를 발견함. 중복되는 `model_transform` 호출을 제거하여 문제를 해결하고, 시각화 결과가 MRE 수치와 일치하도록 수정함.

### 21. MRE 3px 미만 달성을 위한 향후 개선 아이디어 논의
- 새로운 목표 설정: 임상적으로 유의미한 성능을 위해, 랜드마크 예측 MRE를 3px 미만으로 개선하는 것을 새로운 목표로 설정함.
- 아이디어 제시: 목표 달성을 위해 다음과 같은 세 가지 주요 개선 방안을 논의함.
    1.  모델/해상도 강화 (난이도: 쉬움): ResNet-18 대신 `ResNet-50` 등 더 강력한 백본 모델을 사용하고, 입력 이미지 해상도를 256x256에서 `512x512` 등으로 높여 모델이 더 미세한 특징을 학습하도록 함.
    2.  고급 데이터 증강 (난이도: 중간): `albumentations` 라이브러리를 활용하여 Elastic Deformation, 밝기/대비 조절 등 의료 영상에 효과적인 데이터 증강을 추가하여 모델의 강인함과 일반화 성능을 높임.
    3.  히트맵(Heatmap) 기반 접근법 (난이도: 어려움): 현재의 직접 좌표 회귀 방식 대신, 랜드마크 탐지 분야의 표준적인 접근법인 히트맵 예측 방식으로 모델 아키텍처를 근본적으로 변경함. 정확도 향상에 가장 효과적일 것으로 기대되나, 코드 전반에 걸친 수정이 필요한 가장 큰 작업.

### 22. 아이디어 1 (ResNet-50) 적용 및 기존 모델 백업
- 기존 모델 최종 성능 기록: ResNet-18 모델의 최종 최고 성능이 184 에포크에서 달성되었으며, MRE 18.3590, CVM 정확도 0.4357임을 확인함.
- 아이디어 1 구현: MRE 3px 미만 달성을 위해 첫 번째 아이디어를 적용함.
    1. `config.py`의 `IMAGE_SIZE`를 `(512, 512)`로, `VALID_BATCH_SIZE`를 16으로 수정.
    2. `train.py`의 `BATCH_SIZE`를 8로 수정하여 GPU 메모리 부족에 대비.
    3. `model.py`의 백본을 `ResNet-18`에서 `ResNet-50`으로 교체하고, 512x512 입력에 맞는 `fc_input_size` (524288)를 재계산하여 적용.
- 기존 모델 백업: 새로운 훈련과의 충돌을 막기 위해, 기존 `best_model.pth` 파일의 이름을 최종 MRE 값을 반영한 `resnet18_256x256_mre18.4.pth`로 변경하여 백업함.
- 체크포인트 정리: 이름이 변경된 모델을 제외한 나머지 `checkpoints` 폴더를 삭제하여 호환성 문제를 방지함.
- Git 추적 설정: 백업된 모델 파일(`resnet18_256x256_mre18.4.pth`)이 커밋에 포함되도록 `.gitignore`에 예외 규칙을 추가함.

### 23. 아이디어 1 (ResNet-50) 훈련 결과 및 평가
- 훈련 실행: `feature/resnet50-512px` 브랜치에서 ResNet-50 백본과 512x512 해상도로 모델 훈련을 약 100 에포크 동안 진행함.
- 최종 성능: 98 에포크에서 최고 성능을 기록했으며, 결과는 다음과 같음.
    - Landmark MRE (px): 17.2830
    - CVM Accuracy: 0.4357
    - CVM F1-Score: 0.2190
- 결과 분석: 기존 ResNet-18 모델(MRE 18.4px) 대비 성능이 소폭 향상되었으나, 목표치인 3px 미만에는 크게 미치지 못함. 현재의 직접 좌표 회귀 방식의 한계로 판단됨.
- 향후 계획: 단순히 훈련을 더 진행하기보다는, 더 큰 성능 향상을 위해 아이디어 2(고급 데이터 증강) 또는 아이디어 3(히트맵)으로 전환하기로 결정함.

##### 2025.09.22 (5일차) 병원 #####

### 24. 아이디어 2 (고급 데이터 증강) 적용 및 유틸리티 스크립트 리팩토링
- 데이터 증강 파이프라인 구축:
  - `feature/albumentations` 브랜치에서 `albumentations` 라이브러리 기반의 데이터 증강 파이프라인을 `dataset.py`에 구현함.
  - `Affine` (이동, 스케일, 회전), `RandomBrightnessContrast`, `GaussNoise` 등의 변환을 적용함.
  - `torchvision` 기반의 기존 변환 코드를 제거하여 프로젝트 코드의 일관성을 확보함.

- 데이터 로더 오류 디버깅:
  - 증강 적용 시 랜드마크 개수가 변하는 `RuntimeError` 발생.
  - 원인 분석 결과, `ElasticTransform`이 `remove_invisible=False` 설정을 따르지 않는 문제로 확인됨.
  - 안정적인 훈련을 위해 문제가 되는 `ElasticTransform`을 비활성화 조치함.

- 의존성 관리 개선:
  - `requirements.txt`에 `torch`, `torchvision`, `scikit-learn`, `numpy` 등 누락된 주요 라이브러리를 추가함.
  - 의존성 격리를 위해 가상 환경(`venv`) 사용

- 평가 스크립트 리팩토링:
  - `evaluate.py`와 `visualize.py`의 기능을 하나로 통합하여 `evaluate.py`로 단일화함.
  - 새로운 `evaluate.py`는 전체 테스트셋 평가와 더불어, `--visualize-index` 인자를 통해 특정 이미지의 예측 결과 시각화 기능을 선택적으로 수행할 수 있음.
  - 중복되는 `visualize.py` 파일은 삭제함.

### 25. F1 점수 및 정확도(Accuracy)의 의미와 신뢰도 기준
- 정확도(Accuracy)의 한계: 가장 직관적이지만, 데이터 불균형(예: 특정 CVM 단계가 대부분인 경우)이 있을 때 모델의 실제 성능을 왜곡할 수 있음. 예를 들어, 모델이 항상 가장 흔한 클래스만 예측해도 정확도는 높게 나올 수 있음.

- F1 점수(F1-Score)의 중요성: 정밀도(Precision)와 재현율(Recall)의 조화 평균으로, 모든 클래스를 얼마나 균형 있게 잘 예측하는지 종합적으로 보여줌. 특히, 데이터 불균형 상황에서 소수 클래스에 대한 성능까지 측정하므로 모델의 실제 성능을 더 잘 대변함.

- 신뢰도 판단 기준 (CVM 분류 문제의 경우):
  - 최소 기준: 6개 클래스이므로 무작위 추측(약 16.7%)보다는 월등히 높아야 함.
  - 일반적 기준: F1 점수 0.7 이상은 '양호', 0.9 이상은 '매우 뛰어남'으로 평가될 수 있음.
  - 가장 중요한 기준 (의료 분야): '전문가 간 신뢰도' (여러 의사가 동일한 데이터를 얼마나 일치하게 진단하는지)가 AI 모델 성능의 최종 목표치가 됨. 관련 연구들에서 제시하는 F1 점수(보통 0.8 ~ 0.9 이상)를 달성해야 임상적으로 신뢰할 수 있다고 볼 수 있음.

### 26. 아이디어 2-1 (CVM 단독 학습) 실험 및 분석
- 실험 목표: 멀티태스킹이 CVM 분류 성능 저하의 원인인지 확인하기 위해, CVM 분류 작업만 단독으로 학습하는 베이스라인 실험을 진행함.

- 구현:
  - `model_cvm_only.py`: ResNet-18 백본과 CVM 분류 헤드 하나만으로 구성된 단순화된 모델을 새로 정의함.
  - `train_cvm_only.py`: CVM 단독 학습을 위한 전용 훈련 스크립트를 작성함. Early Stopping, LR Scheduler 등은 검증 손실을 기준으로 작동하도록 수정.
  - `dataset.py` 리팩토링: 다양한 이미지 크기(224x224 등)를 지원할 수 있도록 `image_size`를 인자로 받게 수정하고, 이를 사용하는 모든 스크립트(`train.py`, `evaluate.py` 등)를 업데이트함.

- 실험 결과:
  - CVM 단독 학습 결과, F1 점수가 약 0.1~0.2 범위에서 정체되며 학습에 완전히 실패함.

- 결론 및 향후 계획:
  - 문제의 근본 원인이 멀티태스킹이 아님을 확인함. 모델이 두개골 전체 이미지로부터 CVM 단계 구분에 필요한 미세한 특징을 학습하지 못하는 것으로 판단됨.
  - 이에 따라, `ToDo.txt`의 `C12` 항목인 ROI(관심 영역) 기반 파이프라인을 다음 단계로 추진하기로 결정함. (경추 영역만 잘라내어 분류기에 학습시키는 방식)

##### 2025.09.23 (6일차) 병원 #####

### 27. CVM 성능 개선을 위한 ROI 파이프라인 구축 (1단계)
- 목표: CVM 분류 모델의 학습 실패 문제를 해결하기 위해, 경추 영역만 잘라낸 ROI(관심 영역) 이미지를 사용한 훈련 파이프라인을 구축합니다.
- ROI 데이터셋 생성:
    - `preprocess_roi.py` 스크립트를 실행하여 ROI 데이터셋 생성을 완료했습니다. 이 스크립트는 기존 랜드마크 모델을 활용해 원본 이미지에서 경추 영역을 자동으로 잘라내어 `Aariz_ROI` 폴더에 저장합니다.
    - 실행에 앞서, `config.py`에 원본 데이터 경로(`DATASET_PATH`)와 ROI 저장 경로(`ROI_DATASET_PATH`)가 잘못 설정된 문제를 진단하고 수정했습니다.
- ROI 훈련 스크립트 준비:
    - CVM 전용 훈련 스크립트(`train_cvm_only.py`)가 새로 생성된 `Aariz_ROI` 데이터셋을 올바르게 참조하도록 경로 관련 버그를 수정했습니다.
    - 이로써 ROI 기반의 CVM 분류 모델 훈련을 위한 모든 준비를 마쳤습니다.

### 28. ROI 기반 CVM 훈련 실패 및 원인 분석
- 1차 훈련 시도: `memo.txt` 25번 단계에서 준비한 `train_cvm_only.py`를 실행했으나, 체크포인트 폴더가 없어 모델 저장에 실패하는 오류 발생.
- 버그 수정: `train_cvm_only.py`에 폴더를 자동 생성하는 로직을 추가하여 문제를 해결함.
- 2차 훈련 및 결과: 훈련을 재개했으나, F1 점수가 약 0.1에서 정체되며 모델이 의미 있는 학습에 실패했음을 확인함.
- 조치: 학습 실패한 모델은 `cvm_roi_resnet18_f1-0.1.pth`로 백업함.
- 향후 계획: 학습 실패의 가장 유력한 원인인 클래스 불균형 문제를 해결하기 위해, 가중 손실(Weighted Loss)을 도입하여 훈련을 재시도하기로 결정함.

### 29. 가중 손실(Weighted Loss) 실험 및 추가 개선 사항

- 가중 손실 실험: CVM 분류 성능 개선을 위해, 클래스 불균형을 해소하고자 가중 손실(Weighted Cross-Entropy Loss)을 `train_cvm_only.py`에 적용함.
  - 훈련 데이터셋의 클래스 분포를 분석하여 가중치를 계산하고 `nn.CrossEntropyLoss`에 전달함.
- 실험 결과: 가중 손실 적용 후에도 F1 점수가 0.1대에 머무르며 학습에 실패함.
  - 이는 단순 가중 손실만으로는 심각한 클래스 불균형 문제를 해결하기에 부족함을 시사함.
- 기타 개선 사항:
  - 프로젝트 내 모든 모델 파일(.pth)에 `model_` 접두사를 붙여 관리하고, `model_description.txt` 파일을 생성하여 각 모델의 상세 정보를 기록함.
  - `train.py`와 `train_cvm_only.py`가 `yyyymmdd_hhmm_` 형식의 타임스탬프를 포함한 고유한 CSV 로그 파일을 생성하도록 수정하여 훈련 기록 관리를 개선함.
- 향후 계획: 단순 가중 손실만으로는 부족하다고 판단, 더 강력한 불균형 데이터 처리 기법인 포컬 로스(Focal Loss)를 다음 단계로 도입하기로 결정함.

### 30. 포컬 로스(Focal Loss) 적용 실험

- 목표: 가중 손실로도 해결되지 않은 CVM 분류 모델의 학습 실패 문제를 해결하기 위해, 클래스 불균형에 더 효과적인 포컬 로스를 도입함.
- 구현:
  - `focal_loss.py` 파일을 새로 생성하고, PyTorch 기반의 포컬 로스 구현 코드를 추가함.
  - `train_cvm_only.py`를 수정하여 기존 `CrossEntropyLoss` 대신 `focal_loss.py`에서 임포트한 `FocalLoss`를 사용하도록 변경함.
  - 이전 가중 손실 실험에서 계산된 클래스 가중치를 `FocalLoss`의 `alpha` 파라미터로 전달하고, `gamma`는 2.0으로 설정함.
- 향후 계획: 포컬 로스 적용 후 훈련 결과를 분석하여 CVM 분류 성능 개선 여부를 평가할 예정임.

##### 2025.09.24 (7일차) 집 #####

### 31. CVM 모델 학습 실패 분석 및 학습률 조정 실험
- 실험 요약: 조기 종료 `patience`를 30으로 늘리고, 백본 모델을 `ResNet-50`으로 교체하는 등 여러 실험을 진행했으나 CVM 분류 모델의 F1 점수는 여전히 0.1점대에 머무르며 학습에 실패함.
- 원인 분석: 모든 훈련 로그에서 공통적으로 검증 손실(`valid_loss`)이 매우 불안정하게 급등하는 현상이 관찰됨. 이는 현재 학습률(`0.001`)이 너무 높아 모델이 안정적인 최적점을 찾지 못하고 발산(diverging)하고 있을 가능성을 시사함.
- 향후 계획: 모델이 더 안정적으로 수렴할 수 있도록, `train_cvm_only.py`의 학습률을 기존 `0.001`에서 `0.0001`로 10배 낮추는 실험을 진행하기로 결정함.
- 부가 수정: 훈련 로그에 백본 이름이 `ResNet-18`로 고정되어 출력되는 사소한 오류를 수정

### 32. 과적합(Overfitting) 현상 발견 및 데이터 증강 강화 계획
- 실험 결과: 학습률을 `0.0001`로 낮추자 `train_loss`가 처음으로 유의미하게 감소하며 모델이 학습을 시작하는 긍정적 신호를 확인함.
- 문제 분석: 하지만 `valid_loss`는 반대로 급증하며 `train_loss`와의 격차가 크게 벌어지는 전형적인 과적합(Overfitting) 현상이 발생함. 이는 모델이 훈련 데이터는 완벽히 암기하고 있지만, 일반화에는 실패하고 있음을 의미함.
- 향후 계획: 과적합을 억제하기 위해, `dataset_roi_cvm.py`에 `GridDistortion`, `OpticalDistortion` 등 더 강력한 데이터 증강(Data Augmentation) 기법을 추가하여 모델이 훈련 데이터를 쉽게 암기하지 못하도록 하는 실험을 진행하기로 결정함.
- 새 브랜치 생성: feature/stronger-augmentation

### 33. 과적합 해결을 위한 데이터 증강 강화 실험 (1)
 - 목표: memo.txt #32에서 확인된 과적합 현상을 해결하기 위해, 더 강력한 데이터 증강 기법을 적용함.
 - 구현: dataset_roi_cvm.py의 훈련 데이터 변환 파이프라인에 GridDistortion과 OpticalDistortion을 추가함.
- 결과 및 분석: 훈련 결과, train_loss는 감소했지만 valid_loss는 여전히 불안정하고 F1 점수도 개선되지 않음. 과적합 문제가 해결되지 않았으며, 오히려 증강 기법이 너무 과도하여 학습을 방해했을 가능성을 확인함.

### 34. 데이터 증강 강도 완화 실험 (2)
 - 목표: 이전 실험의 증강 기법이 너무 과도했을 가능성을 확인하기 위해, 증강의 강도를 낮추어 실험함.
 - 구현: dataset_roi_cvm.py의 GridDistortion과 OpticalDistortion의 변형 강도(distort_limit)를 기본값보다 낮은 0.1로 설정하여 수정함.
 - 결과 및 분석: 결과는 이전 실험과 거의 동일했으며, 여전히 과적합 문제가 해결되지 않음. 이를 통해 데이터 증강의 강도가 문제의 핵심이 아님을 확인함.

 ### 35. 학습률 추가 조정 실험 (3)
 - 목표: 모델의 불안정한 수렴 문제를 해결하기 위한 마지막 하이퍼파라미터 조정 시도로, 학습률을 대폭 낮추어 안정적인 학습을 유도함.
 - 구현: train_cvm_only.py의 학습률을 기존 0.0001에서 0.00001로 10배 더 낮춤.
 - 결과 및 분석: 훈련 초반, valid_loss가 train_loss와 근접하게 시작하는 긍정적 신호가 있었으나, 이내 다시 급증하며 발산함. F1 점수는 오히려 이전보다도 낮게 측정됨. 이로써 하이퍼파라미터 조정만으로는 문제를 해결할 수 없다는 결론에 도달함.

 ### 36. 최종 결론 및 접근법 전환
 - 최종 결론: ROI 이미지로부터 직접 CVM 단계를 분류하는 현재의 접근법은 근본적인 한계에 도달함. 학습률, 데이터 증강, 모델 구조 등 가능한 모든 하이퍼파라미터 튜닝 시도가 CVM 분류 성능 개선에 실패함.
 - 향후 계획: memo.txt #21에서 제안되었던 히트맵(Heatmap) 기반 접근법으로 프로젝트의 방향을 완전히 전환하기로 결정함. 이 방법은 모델이 먼저 CVM 단계 판별에 필수적인 해부학적 랜드마크의 위치를 히트맵으로 예측하고, 그 예측된 좌표를 기반으로 기하학적 특징을 계산하여 최종 단계를 분류하는 방식임. 이는 보다 안정적이고 높은 성능이 기대되는 표준적인 접근법으로, 다음 개발 단계의 핵심 목표가 될 것임.

### 37. 히트맵 기반 모델 1차 훈련 성공 및 미세 조정(Fine-tuning) 계획
  - 접근법 전환: CVM 직접 분류의 한계를 확인하고, feature/heatmap-approach 브랜치를 생성하여 히트맵 기반의 랜드마크 예측 모델 개발을 시작함.
  - 구현: dataset.py, model.py, train.py를 히트맵 예측에 맞게 전면 재작성함.  HeatmapDataset은 증강된 이미지와 타겟 히트맵을 생성하고, HeatmapModel은 ResNet-50 백본과 업샘플링 헤드를 통해 히트맵을 출력하도록 설계함. train.py는 MSE 손실을 사용하여 모델을 훈련하고, 예측된 히트맵의 최대값으로부터 좌표를 추출하여 MRE를 계산함.
  - 1차 훈련 결과: 새로운 히트맵 모델의 훈련이 성공적으로 진행됨. 검증 MRE(valid_mre)가 초반에 잠시 급등했으나, 이내 안정적으로 감소하여 약 38.4px에서 수렴하는 매우 긍정적인 결과를 얻음. 이는 히트맵 접근법의 유효성을 명백히 입증함.
  - 향후 계획: 현재 38.4px인 MRE를 더욱 향상시키기 위해, 다음 단계로 '얼어있는' ResNet-50 백본을 '녹여' 모델 전체를 낮은 학습률로 미세 조정(Fine-tuning)하는 전략을 실행하기로 결정함.

##### 2025.09.25 (8일차) 집 #####

### 38. 고해상도(512x512) 입력을 사용한 2차 훈련 준비
  - 목표: 256x256 해상도에서 달성한 MRE 4.5px의 한계를 돌파하기 위해, 모델에 더 상세한 정보를 제공하는 고해상도 이미지로 훈련을 진행함.
  - 사전 작업:
      1.  256x256 해상도에서 얻은 최상의 모델(MRE 4.5px)을 model_heatmap_resnet50_finetuned_mre4.5.pth로 루트 경로에 백업함.
      2.  model_description.txt에 해당 모델의 정보를 기록함.
  - 구현:
      - config.py: IMAGE_SIZE를 (512, 512)로 상향 조정함.
      - train.py: 고해상도 훈련을 위해 하이퍼파라미터를 다음과 같이 수정함.
          - BATCH_SIZE: GPU 메모리 관리를 위해 4로 축소.
          - HEATMAP_OUTPUT_SIZE: 모델 구조에 맞춰 (128, 128)로 변경.
          - PRETRAINED_MODEL_PATH: 훈련을 이어가기 위해 방금 백업한 mre4.5.pth 모델을 불러오도록 설정.
          - 훈련 전략: 불러온 모델의 백본을 다시 동결시켜, 새로운 해상도에 맞게 헤드 부분을 15 에포크 동안 먼저 훈련시킨 후, 모델 전체를 미세 조정하는 2단계 훈련 방식을 채택함.

### 39. 고해상도(512x512) 1차 훈련 및 성능 저하 분석
  - 목표: MRE 4.5px의 한계를 돌파하기 위해, 입력 이미지 해상도를 512x512로 높여 훈련을 진행함.
  - 결과: MRE가 약 4.5px에서 약 5.4px로 오히려 성능이 저하됨.
  - 분석: 훈련 로그를 검토한 결과, 모델 자체는 안정적으로 학습되나 최종 MRE가 개선되지 않음. 이는 128x128로 커진 히트맵에 비해 가우시안 분포의 sigma 값이 2로 너무 작아, 타겟이 과도하게 뾰족해져서 학습에 부정적인 영향을 주었을 가능성이 높다고 판단됨.
  - 향후 계획: 타겟 히트맵을 더 부드럽게 만들어 모델의 학습을 돕기 위해, train.py의 HEATMAP_SIGMA 값을 2에서 4로 상향 조정한 후 동일한 조건에서 훈련을 재실행하기로 결정함.

### 40. 고해상도(512x512) 2차 훈련 (Sigma 값 조정) 및 데이터 증강 강도 재조정 계획
  - 목표: 512px 해상도에서 성능이 저하된 원인이 '뾰족한' 히트맵 타겟 때문일 것이라는 가설을 검증하기 위해, HEATMAP_SIGMA 값을 4로 높여 훈련을 진행함.
  - 결과: MRE가 약 5.4px에서 약 5.8px로 오히려 성능이 추가로 저하됨.
  - 분석: 이 실험을 통해, 512px 고해상도에서도 sigma=2로 설정된 더 명확하고 뾰족한 타겟이 모델 학습에 더 유리하다는 결론을 얻음. 따라서 성능 저하의 원인은 sigma 값이 아니며, 해상도에 비해 데이터 증강의 강도가 너무 과하여 모델이 정밀한 특징을 학습하는 데 방해를 받고 있을 가능성이 가장 유력함.
  - 향후 계획:
      1.  train.py의 HEATMAP_SIGMA 값을 더 좋은 결과를 보였던 2로 되돌림.
      2.  dataset.py의 Affine 변환 강도를 낮추어(회전, 스케일, 이동 범위 축소), 모델이 과도한 왜곡 없이 이미지의 미세한 특징을 학습하도록 유도하는 다음 실험을 진행하기로 결정함.

##### 2025.09.26 (9일차) 집 #####

### 41. 고해상도(512x512) 3차 훈련 (증강 강도 완화) 및 U-Net 아키텍처 도입 계획
  - 목표: 512px 해상도에서의 성능 저하가 과도한 데이터 증강 때문이라는 가설을 검증하기 위해, Affine 변환의 강도를 낮추어 훈련을 진행함.
  - 결과: MRE가 약 5.5px에서 수렴하며, 이전 실험(MRE 5.4px)과 비교해 유의미한 성능 개선을 확인하지 못함.
  - 최종 분석:
      - 512px 고해상도에서 sigma 값, 데이터 증강 강도를 조절했음에도 MRE가 4.5px(256px 모델)의 벽을 넘지 못함.
      - 이는 현재 모델의 단순한 업샘플링(Upsampling) 구조가 고해상도 이미지의 세부적인 위치 정보를 활용하는 데 근본적인 한계가 있음을 명백히 시사함.
  - 향후 계획:
      - 현재의 성능 정체를 돌파하기 위해, 모델 아키텍처를 근본적으로 개선하기로 결정함.
      - 랜드마크 탐지 분야의 표준 아키텍처인 U-Net 구조를 도입하여, 업샘플링 과정에서 다운샘플링 과정의 풍부한 위치 정보(스킵 커넥션)를 활용하도록 model.py를 수정하는 다음 단계를 진행할 것임.

### 42. U-Net 아키텍처 도입 및 1차 훈련
  - 목표: 512px 고해상도에서 성능이 정체되는 문제의 원인이 '단순한 업샘플링 구조' 때문이라는 가설을 검증하고, 스킵 커넥션(Skip Connection)이 적용된 U-Net 아키텍처로 이를 해결하고자 함.
  - 구현:
      - model.py: UNetHeatmapModel을 새로 구현함. ResNet-50의 각 인코더 블록에서 나오는 특징 맵을 디코더의 각 업샘플링 블록에 연결하는 스킵 커넥션을 추가함.
      - train.py: 새로운 UNetHeatmapModel을 처음부터(from scratch) 훈련하도록 수정함.
  - 결과:
      - U-Net 아키텍처 도입은 성공적이었음. 모델은 안정적으로 학습하여 MRE 5.03px를 달성함.
      - 이는 512px 해상도에서 기록한 최고의 성능이지만, 여전히 256px 모델의 최고 기록(MRE 4.5px)에는 미치지 못함.
  - 분석:
      - U-Net 구조의 우수성은 입증되었으나, 모델을 처음부터 훈련시켰기 때문에 여러 단계의 튜닝을 거친 256px 모델의 최적화된 가중치를 따라잡기에는 학습이 부족했던 것으로 보임.
  - 향후 계획:
      - 최고의 아키텍처(U-Net)와 최고의 가중치(MRE 4.5px 모델)를 결합하는 전이 학습(Transfer Learning)을 시도하기로 결정함.
      - train.py를 수정하여, UNetHeatmapModel을 model_heatmap_resnet50_finetuned_mre4.5.pth의 가중치로 초기화한 후 훈련을 시작할 예정임.

### 43. U-Net 전이 학습(Transfer Learning) 및 최종 성능 확인
  - 목표: 최고의 아키텍처(U-Net)와 최고의 가중치(256px, MRE 4.5px 모델)를 결합하여, 512px 해상도에서 5.0px의 성능 한계를 돌파하고자 함.
  - 구현:
      - train.py를 수정하여, UNetHeatmapModel의 백본 가중치를 model_heatmap_resnet50_finetuned_mre4.5.pth 파일로부터 불러와 초기화하는 전이 학습 로직을 구현함.
      - 512px 이미지로 2단계(헤드 훈련, 전체 미세 조정) 훈련을 진행함.
  - 결과:
      - 최종 MRE ~5.0px를 기록함. 이는 U-Net을 처음부터 훈련시킨 이전 실험과 사실상 동일한 결과임.
  - 최종 분석 및 결론:
      - 전이 학습은 최종 성능 개선에 영향을 주지 못함: U-Net 아키텍처가 충분히 강력하여, 사전 훈련된 가중치의 도움 없이도 스스로 최적의 특징을 학습해 낼 수 있음을 시사함.
      - 현재 접근법의 한계 도달: 256px, 512px 해상도, 단순 히트맵, U-Net, 전이 학습 등 가능한 거의 모든 실험을 시도했으나, 256px 모델의 MRE 4.5px가 현재 아키텍처와 데이터셋으로 달성할 수 있는 최상의 성능이라는 결론에 도달함. 512px 고해상도를 이용한 성능 개선 시도는 더 이상 유의미한 진전을 보기 어려울 것으로 판단됨.

### 44. 랜드마크 탐지 모델링 최종 결론 및 향후 방향 설정
  - 최종 결론:
      - 수많은 실험(해상도, 아키텍처, 하이퍼파라미터, 전이 학습 등)을 통해, 현재 데이터셋과 접근법으로는 256px 해상도 기반의 히트맵 모델이 달성한 MRE 4.5px가 최상의 성능임을 확인함.
      - 512px 고해상도 모델은 U-Net 아키텍처로 개선했음에도 MRE 5.0px의 벽을 넘지 못했으며, 이는 현재 접근법의 한계로 판단됨.
      - 이에 따라, 랜드마크 탐지 모델의 MRE를 개선하기 위한 추가적인 실험은 잠정적으로 중단하기로 결정함.

  - 향후 방향 논의:
      - 랜드마크 탐지 성능이 안정화된 현시점에서, 프로젝트의 최종 목표인 CVM 단계 분류를 위한 다음 단계에 대해 3가지 선택지를 논의함.
      1.  CVM 분류기 개발 (권장): 현재 최상의 랜드마크 모델(MRE 4.5px)을 활용하여 좌표를 추출하고, 이 좌표로부터 CVM 단계 분류에 필요한 기하학적 특징을 계산하여 새로운 분류기를 훈련하는 방식.
      2.  MRE 추가 최적화 (비권장): MRE 4.5px 이하로 성능을 더 개선하기 위해 추가적인 모델링 실험을 계속하는 방식. (노력 대비 효과가 적을 것으로 예상)
      3.  멀티태스크 재도전 (위험 높음): 랜드마크 탐지와 CVM 분류를 동시에 수행하는 새로운 멀티태스크 모델을 다시 개발하는 방식. (과거 실패 경험으로 위험 부담이 큼)

  - 최종 결정:
      - 논의 결과, 가장 합리적이고 프로젝트의 최종 목표 달성 가능성이 높은 선택지 1을 채택하기로 결정함.
      - 다음 단계로, feature/cvm-classification-from-landmarks와 같은 새 브랜치를 생성하여, 예측된 랜드마크를 활용한 CVM 분류기 개발을 시작할 것임.

### 45. CVM 분류 단계 진입 및 데이터셋의 근본적 한계 확인
  - 새로운 국면: 랜드마크 탐지 모델링을 성공적으로 마무리하고, 그 성과를 바탕으로 CVM 분류 모델을 개발하기 위해 feature/cvm-classification-from-landmarks 브랜치를 생성함.

  - 1단계 (랜드마크 예측):
      - 목표: 최고 성능의 랜드마크 모델(MRE 4.5px)을 사용하여, 전체 데이터셋의 랜드마크 좌표를 일괄적으로 예측하고 파일로 저장하는 predict_landmarks.py 스크립트를 개발함.
      - 과정: 스크립트 개발 중 tqdm 라이브러리 부재, ImportError, RuntimeError 등 다수의 오류를 해결하며 스크립트를 완성함.

  - 2단계 (특징 공학의 난관):
      - 목표: 예측된 랜드마크 좌표로부터 CVM 단계 분류에 필요한 기하학적 특징(예: 척추의 오목함, 비율)을 계산하고자 함.
      - 문제 발생: 이를 위해서는 29개의 랜드마크 중 어떤 것이 경추(C2, C3, C4)에 위치하는지 식별해야 했음.
      - 시각화 및 전문가 검증: 랜드마크 식별을 위해 visualize_landmarks.py를 작성하여 이미지에 모든 랜드마크와 번호를 표시함. 직접 이미지를 확인한 결과, 데이터셋의 29개 랜드마크 중 경추에 위치한 랜드마크는 단 하나도 없음을 최종적으로 확인함.

  - 최종 결론:
      - 기하학적 접근 불가: 경추 랜드마크의 부재로 인해, 우리가 계획했던 '기하학적 특징 계산' 방식의 CVM 분류는 원천적으로 불가능함.
      - 데이터 기반 접근 기각: "29개 랜드마크 좌표와 CVM 단계 간의 상관관계가 있을 수 있다"는 가설 또한 임상적 근거 부족함.
      - Aariz 데이터셋의 한계 명확화: 과거에 실패했던 '이미지 직접 분류' 방식과 더불어, 이번 '랜드마크 기반 분류' 방식까지 불가능함이 확인됨에 따라, "공개된 Aariz 데이터셋의 주석(annotation)만으로는 신뢰도 있는 CVM 분류 모델을 훈련시킬 수 없다"는 최종 결론에 도달함.

  - 프로젝트 성과:
      - 비록 CVM 분류는 데이터셋의 한계로 완수하지 못했으나, 그 과정에서 MRE 4.5px의 고성능 랜드마크 탐지 모델을 성공적으로 개발했으며, 다양한 실험을 통해 모델링 방법론을 체계적으로 구축하고 기록한 것을 이 프로젝트의 최종 성과로 삼음.

##### 2025.09.27 (10일차) 집 #####

### 46. CVM 분류 모델 재도전 및 U-Net 아키텍처 적용 계획
  - 배경: CVM 분류를 위한 기하학적 특징 계산 방식이 데이터셋의 한계로 불가능해진 상황에서, 과거에 실패했던 'ROI 이미지 직접 분류' 방식을 재검토함.
  - 새로운 가설: 과거의 실패는 단순한 분류 모델(ResNet)의 한계 때문이었을 수 있음. 랜드마크 탐지에서 뛰어난 성능을 보인 U-Net 아키텍처의 형태 분석 능력을 활용하면, ROI 이미지에서 직접 CVM 단계를 학습하는 데 성공할 수도 있다는 새로운 가설을 수립함.
  - 최종 결정: 이 가설을 검증하기 위해, U-Net 아키텍처를 CVM 분류에 직접 적용하는 마지막 실험을 진행하기로 결정함.
  - 향후 계획:
      1. 새 브랜치 feature/cvm-unet-classifier 생성함.
      2. 기존 UNetHeatmapModel의 구조를 차용하되, 마지막 출력층만 6개의 CVM 단계를 예측하는 분류기(Classifier)로 수정한 UNetCVMClassifier 모델을 새로 개발할 예정
      3. train_cvm_only.py 스크립트를 수정하여 이 새로운 U-Net 모델을 기존의 Aariz_ROI 데이터셋으로 훈련시키는 실험을 진행할 예정 

  ### 47. 최종 실험: U-Net을 이용한 CVM 직접 분류 및 프로젝트 최종 결론
  - 마지막 시도: 'U-Net 아키텍처의 형태 분석 능력이라면 가능할 수 있다'는 마지막 가설을 검증하기 위해, UNetCVMClassifier 모델을 ROI 이미지에 직접 적용하여 CVM 분류 훈련을 진행함.
  - 최종 실험 결과: F1 점수가 0.02점에서 머무르며, U-Net 아키텍처 역시 CVM 단계를 학습하는 데 완전히 실패함.
  - 프로젝트 최종 결론:
      - 수많은 시도와 검증을 통해, Aariz 데이터셋의 공개된 주석만으로는 CVM 단계 분류 모델을 개발하는 것이 불가능하다는 결론에 최종적으로 도달함.
      - 이 프로젝트의 공식적인 성과는 MRE 4.5px의 고성능 랜드마크 탐지 모델 개발로 정의하고, 모든 실험을 공식적으로 종료함.

##### 2025.09.28 (11일차) 집 #####

### 48. CVM 분류 접근법에 대한 주요 논문 검토
    - CVM 분류 실패의 원인을 분석하고 새로운 아이디어를 얻기 위해, 골 연령 측정 관련 주요 딥러닝 논문 두 편을 검토함.
    - 논문 1: 'Computerized Bone Age Estimation...' (Kim et al., AJR 2017)
      - 내용: 수골(hand-wrist) X-ray 사진을 이용한 딥러닝 기반 자동 뼈 나이 측정 시스템의 높은 정확도와 효율성을 입증함.
      - 시사점: AI를 이용한 골 연령 평가의 전반적인 성공 가능성을 확인. CVM 분석에도 유사한 접근이 유효할 것이라는 확신을 얻음.
    - 논문 2: 'Deep focus approach...' (Seo et al., JDS 2023)
      - 내용: 측모 세팔로 영상에서 경추(cervical vertebrae) 영역만 정밀하게 분할(segmentation)한 뒤, 이를 회귀(regression) 모델에 입력하여 뼈 나이를 성공적으로 예측함.
      - 시사점: CVM 분석의 성공 핵심이 '정밀한 관심 영역(ROI) 확보'에 있음을 명확히 보여줌. 이는 우리가 부정확한 ROI로 CVM 학습에 실패했던 원인을 설명해주며, '분할 우선(segmentation-first)'이라는 새로운 해결책과 라벨링 최소화 전략('안 1, 2, 3')을 수립하는 데 결정적인 아이디어를 제공함.

 ### 49. CVM 분류 재도전을 위한 신규 방법론 탐색
    - 배경: 기존 Aariz 데이터셋의 한계와 관련 논문들의 시사점을 바탕으로, CVM 분류 모델 개발을 위한 새로운 방법론을 탐색함.
    - 1차 아이디어 (논문 2 기반 "Deep Focus" 접근): 경추 영역을 정밀하게 분할한 뒤 분류 모델을 학습시키는 2단계 접근법을 검토. 하지만, 이를 위해서는 픽셀 단위의 수동 라벨링 작업이 선행되어야 하는 큰 부담이 있음을 확인함.
    - 대안 탐색 (라벨링 최소화): 라벨링 작업을 피하거나 최소화하기 위해 다음 두 가지를 조사함.
        1.  사전 훈련된 경추 분할 모델 검색: 웹 검색을 통해 바로 사용 가능한 모델을 찾아보았으나, 연구 논문만 존재할 뿐 다운로드하여 활용할 수 있는 공개 모델은 찾지 못함.
        2.  CVM 학습용 신규 데이터셋 검색: CVM 단계 학습에 더 적합한 다른 공개 데이터셋을 찾아보았으나, 결국 현재 사용 중인 Aariz 데이터셋의 공식 출처 논문으로 귀결됨. 새로운 데이터셋 확보는 실패함.
    - 결론: 외부의 준비된 모델이나 데이터셋을 활용하는 '쉬운 길'은 없음을 확인함. 결국 우리가 가진 Aariz 데이터셋을 활용하되, 라벨링 비용을 최소화하는 새로운 전략 수립이 필요하다는 결론에 도달함.

 ### 50. 라벨링 최소화를 위한 3가지 대안 전략 수립 및 논의
    - 목표: 완전 수동 라벨링의 부담을 줄이면서 CVM 분류 성능을 극대화하기 위한 세 가지 구체적인 실행 계획을 수립함.
    - 대안 1 (무라벨 접근): MIL(Multiple Instance Learning)을 도입. 위치 라벨 없이 이미지의 여러 패치(조각)들로부터 모델이 스스로 의미 있는 영역(경추)을 찾아내 CVM 단계를 학습하는 방식. 라벨링이 전혀 필요 없는 장점이 있으나, 학습 안정성이 떨어질 위험이 있음.
    - 대안 2 (최소 박스 라벨 접근): 능동 학습(Active Learning)을 결합. 소수의 이미지(50~100개)에 경계 박스(bounding box)만 라벨링하여 초기 모델을 만들고, 모델이 헷갈려하는 이미지만을 점진적으로 추가 라벨링하여 효율을 극대화하는 방식. 실용성과 성능의 균형이 가장 좋음.
    - 대안 3 (반자동 분할 접근): SAM(Segment Anything Model)과 같은 최신 AI 도구를 활용. 수동으로 이미지당 1~2번의 클릭만으로 정밀한 분할 마스크를 생성하고, 이를 기반으로 형상 특징을 추출하여 분류기를 학습하는 방식. 라벨 품질과 모델의 해석 가능성을 가장 높일 수 있음.
    - 향후 계획: 위 세 가지 대안의 장단점을 비교 분석했으며, 다음 단계로 이 중 하나의 전략을  선택하여 CVM 분류 모델 개발을 본격적으로 재개하기로 결정함.
    
##### 2025.09.29 (12일차) 집 #####

 ### 51. '안 1' (MIL) 실험 준비 및 디버깅
    - 목표: '안 1' (라벨링 없는 MIL 접근법)의 실행 가능성을 검증하기 위해 코드 구현 및 실험 환경 구축.
    - 브랜치 변경: feature/segmentation-first-cvm 브랜치 이름이 현재 논의와 맞지 않아, 더 포괄적인 feature/advanced-cvm-strategy로 변경함.
    - 신규 파일 구현:
      - dataset_mil.py: 이미지 하단 영역에서 여러 개의 패치를 무작위로 샘플링하는 MILDataset 클래스 구현.
      - model_mil.py: ResNet-18 백본과 어텐션 풀링을 사용하는 AttentionMIL 모델 구현.
      - train_mil.py: 서열 회귀를 위한 CORAL 손실 함수와 Kappa/MAE 등 평가지표를 포함한 훈련 스크립트 구현.
    - 주요 디버깅: 훈련 시작 과정에서 발생한 다수의 오류를 순차적으로 해결함.
      - ImportError: dataset_mil.py가 CVM 라벨을 직접 읽도록 수정하여 해결.
      - SyntaxError: model_mil.py의 불필요한 테스트 코드를 제거하여 해결.
      - AttributeError: config.py에 누락된 BATCH_SIZE 변수를 추가하여 해결.
      - RuntimeError: model_mil.py의 모델 구조에 풀링 레이어를 추가하여 텐서 크기 불일치 문제 해결.

 ### 52. '안 1' (MIL) 1차 훈련 및 결과 분석
    - 실행: train_mil.py를 실행하여 '안 1' 모델의 훈련을 약 77 에포크 동안 진행함.
    - 결과 분석:
      - 긍정적: train_loss가 꾸준히 감소하고, 서열 예측의 정확도를 더 잘 나타내는 kappa 점수가 최대 0.44까지 도달. 이는 라벨링 없이도 모델이 CVM 단계의 순서를 어느 정도 학습했음을 의미하며, 이전의 직접 분류 시도(F1-score 0.02)에 비해 크게 발전한 결과임.
      - 부정적: valid_loss가 감소하지 않고 train_loss와 격차가 벌어지는 과적합 현상이 뚜렷하며, 성능 또한 최고점 이후 정체 상태를 보임.
    - 결론: '안 1'은 가능성을 보였으나, 단독으로 임상에 적용할 만한 성능에 도달하기는 어렵다고 판단. 해당 실험 결과를 의미 있는 베이스라인(baseline)으로 확보하고 훈련을 중단하기로 결정함.

 ### 53. '안 2' (최소 박스 라벨) 접근법으로 전환 및 준비
    - 다음 계획: '안 1'의 결과를 바탕으로, 더 현실적이고 높은 성능이 기대되는 '안 2' 전략으로 전환하기로 결정함.
    - 사용자 액션 아이템: '안 2'의 첫 단계인 초기 학습 데이터(seed set) 구축을 위해, labelme 도구를 사용하여 약 50~100개의 훈련 이미지에 경추 영역을 감싸는 경계 박스(bounding box)를 라벨링할 예정. (라벨명: vertebrae_roi)
    - 향후 계획: 라벨링이 완료되면, 해당 데이터를 사용하여 경량 객체 탐지 모델을 훈련시키는 다음 단계로 진행할 것임.